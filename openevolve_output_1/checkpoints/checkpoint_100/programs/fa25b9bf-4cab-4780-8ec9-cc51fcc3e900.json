{"id": "fa25b9bf-4cab-4780-8ec9-cc51fcc3e900", "code": "#include <cstdint>\n#include <unordered_map>\n#include <set>\n\ntypedef uint64_t obj_id_t;\n\nclass CacheManager {\nprivate:\n    // GDSF with frequency aging: track frequency and size for each object.\n    struct CacheObject {\n        uint64_t freq;\n        uint64_t size;\n        uint64_t timestamp;\n        std::set<std::tuple<double, uint64_t, obj_id_t>>::iterator pqit;\n    };\n    // Priority queue node: tuple for easy erase and reinsert\n    // (priority, timestamp, obj_id)\n    std::set<std::tuple<double, uint64_t, obj_id_t>> priority_set;\n    std::unordered_map<obj_id_t, CacheObject> cache_map;\n    uint64_t counter = 0;\n    double last_evict_pri = 0.0;\n\n    // Slightly decrease freq on every eviction to \"age\" frequency counts\n    // Remove frequency aging for simplicity and to boost recency bias\n    // This avoids global rescoring that can cause massive churn.\n    void age_frequencies() {\n        // No-op: remove explicit frequency aging\n    }\n\n    double calc_pri(uint64_t freq, uint64_t size) {\n        // More aggressively boost tiny objects, sublinear freq, stronger recency\n        double small_bonus = (size <= 8) ? 3.0 : (size <= 64) ? 1.0 : 0.0;\n        double freq_term = pow(double(freq), 0.85); // sublinear frequency scaling\n        if (size == 0) return last_evict_pri + (freq_term + small_bonus) * 1e6 + counter * 1e-3;\n        return last_evict_pri + (freq_term + small_bonus) * 1e6 / size + counter * 1e-3;\n    }\n\npublic:\n    bool find(obj_id_t obj_id) {\n        auto it = cache_map.find(obj_id);\n        if (it == cache_map.end()) return false;\n        // Erase from set using iterator (O(log N))\n        priority_set.erase(it->second.pqit);\n        // More aggressive tiny object bump, sublinear freq increment\n        if (it->second.size <= 8)\n            it->second.freq += 3;\n        else if (it->second.size <= 64)\n            it->second.freq += 2;\n        else\n            it->second.freq += 1;\n        it->second.timestamp = ++counter;\n        double new_pri = calc_pri(it->second.freq, it->second.size);\n        auto pqit = priority_set.insert({new_pri, it->second.timestamp, obj_id}).first;\n        it->second.pqit = pqit;\n        return true;\n    }\n\n    void insert(obj_id_t obj_id, uint64_t obj_size) {\n        auto it = cache_map.find(obj_id);\n        if (it != cache_map.end()) {\n            find(obj_id);\n            return;\n        }\n        // Aggressively favor very small and small objects on insert\n        uint64_t freq = (obj_size <= 8) ? 3 : (obj_size <= 64) ? 2 : 1;\n        uint64_t ts = ++counter;\n        double pri = calc_pri(freq, obj_size);\n        auto pqit = priority_set.insert({pri, ts, obj_id}).first;\n        cache_map[obj_id] = {freq, obj_size, ts, pqit};\n    }\n\n    obj_id_t evict() {\n        if (priority_set.empty()) return 0;\n        auto it = priority_set.begin();\n        obj_id_t victim = std::get<2>(*it);\n        last_evict_pri = std::get<0>(*it);\n        priority_set.erase(it);\n        cache_map.erase(victim);\n        // No global frequency aging or rescoring\n        return victim;\n    }\n};", "language": "python", "parent_id": "da0e6924-147b-4087-abbc-3b5c7716390b", "generation": 5, "timestamp": 1763754591.3350348, "iteration_found": 100, "metrics": {"combined_score": -Infinity}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 6 lines with 7 lines\nChange 2: Replace 16 lines with 18 lines\nChange 3: Replace 13 lines with 13 lines", "parent_metrics": {"combined_score": 0.8508, "miss_ratio_4": 0.3666, "miss_ratio_45": 0.2546, "miss_ratio_450": 0.1492}, "island": 1}, "prompts": {"diff_user": {"system": "You are an expert C++ programmer specializing in high-performance cache eviction algorithms.\nYour task is to implement a C++ class named `CacheManager`.\n\nYou MUST provide the complete, raw C++ code, starting with #include.\n\nCRITICAL: The generated code MUST end with the final '};' that closes the class.\n\nCRITICAL: The class MUST have three public methods with these EXACT signatures. DO NOT change them:\n- `bool find(obj_id_t obj_id)`\n- `void insert(obj_id_t obj_id, uint64_t obj_size)`\n- `obj_id_t evict()`\n\nThe class MUST NOT have a custom constructor. It must use the default constructor.\n\nHere is an example of the required structure. You can change the private members and the logic inside the functions, but NOT the public class name or method signatures.\n\n```cpp\n#include <cstdint>\n#include <iomanip>\n#include <iostream>\n#include <set>\n#include <string>\n#include <unordered_map>\n\ntypedef uint64_t obj_id_t;\n\n/**\n* Implements the Greedy-Dual-Size-Frequency (GDSF) eviction policy.\n*\n* This class manages the cache eviction state. It tracks objects,\n* their sizes, and their frequencies to calculate a priority for\n* eviction. It evicts the object with the *lowest* priority.\n*\n* Priority (H-value) is calculated as: L + (Frequency / Size)\n* where 'L' is the priority of the last evicted item.\n*/\nclass CacheManager {\nprivate:\n  /**\n  * Node stored in the priority queue (std::set).\n  *\n  * We use std::set as a min-priority queue. It stores nodes\n  * ordered by priority, then by a timestamp as a tie-breaker.\n  */\n  struct PQNode {\n    double priority;\n    uint64_t timestamp; // Tie-breaker, incremented on each access\n    obj_id_t id;\n\n    // Constructor\n    PQNode(double p, uint64_t ts, obj_id_t i)\n        : priority(p), timestamp(ts), id(i) {}\n\n    // Comparison operator for std::set\n    // Orders by priority (lowest first), then timestamp\n    bool operator<(const PQNode &other) const {\n      if (priority != other.priority) {\n        return priority < other.priority;\n      }\n      return timestamp < other.timestamp;\n    }\n  };\n\n  /**\n  * Metadata for each object stored in the cache.\n  *\n  * Stored as the value in the main `cache_objects` map.\n  */\n  struct CacheObject {\n    uint64_t size;\n    uint64_t frequency;\n    // An iterator pointing to this object's entry in the\n    // priority_queue set. This allows for O(log N) removal\n    // during a `find` operation.\n    std::set<PQNode>::iterator pq_iterator;\n  };\n\n  /**\n  * Main lookup map.\n  *\n  * Maps an object's ID to its metadata (size, freq, and\n  * iterator into the priority queue).\n  */\n  std::unordered_map<obj_id_t, CacheObject> cache_objects;\n\n  /**\n  * The priority queue.\n  *\n  * Implemented as an std::set to keep items sorted by priority\n  * and allow for efficient removal from anywhere in the queue.\n  * The item at `priority_queue.begin()` is the eviction victim.\n  */\n  std::set<PQNode> priority_queue;\n\n  /**\n  *  The 'L' value in GDSF.\n  *\n  * This is the priority of the last item that was evicted.\n  * It's used as the base priority for all new and re-prioritized items.\n  */\n  double pri_last_evict = 0.0;\n\n  /**\n  * A simple counter to use as a timestamp for tie-breaking.\n  *\n  * This ensures FIFO-like behavior for items with the same priority.\n  */\n  uint64_t request_counter = 0;\n\n  /**\n  * Helper function to calculate an object's priority (H-value).\n  *\n  * From the original code: pri = L + (freq * 1.0e6 / size)\n  * The 1.0e6 is a scaling factor to keep the (freq/size)\n  * component significant.\n  */\n  double calculate_priority(uint64_t freq, uint64_t size) {\n    if (size == 0) {\n      return pri_last_evict + (double)(freq) * 1.0e6;\n    }\n    return pri_last_evict + (double)(freq) * 1.0e6 / size;\n  }\n\npublic:\n  /**\n  * Default constructor.\n  */\n  CacheManager() = default;\n\n  /**\n  * Finds an object in the cache.\n  *\n  * If the object is found, its frequency is incremented, its\n  * priority is recalculated, and its position in the\n  * priority queue is updated.\n  *\n  * @param obj_id The ID of the object to find.\n  * @return true if the object was found (a hit), false otherwise (a miss).\n  */\n  bool find(obj_id_t obj_id) {\n    auto map_iter = cache_objects.find(obj_id);\n\n    if (map_iter == cache_objects.end()) {\n      return false;\n    }\n\n    CacheObject &obj = map_iter->second;\n    priority_queue.erase(obj.pq_iterator);\n    obj.frequency += 1;\n    double new_pri = calculate_priority(obj.frequency, obj.size);\n\n    PQNode new_node(new_pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    obj.pq_iterator = set_iter;\n\n    return true;\n  }\n\n  /**\n  * Inserts a new object into the cache.\n  *\n  * Assumes this is called after a `find` reported a miss.\n  * If the object already exists, this function will behave\n  * like `find()` and update its priority.\n  *\n  * @param obj_id The ID of the object to insert.\n  * @param obj_size The size of the object (required for GDSF).\n  */\n  void insert(obj_id_t obj_id, uint64_t obj_size) {\n    if (cache_objects.count(obj_id)) {\n      find(obj_id);\n      return;\n    }\n\n    CacheObject new_obj;\n    new_obj.size = obj_size;\n    new_obj.frequency = 1;\n\n    double pri = calculate_priority(new_obj.frequency, new_obj.size);\n    PQNode new_node(pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    new_obj.pq_iterator = set_iter;\n    cache_objects[obj_id] = new_obj;\n  }\n\n  /**\n  * Selects, removes, and returns the victim object to evict.\n  *\n  * The victim is the object with the *lowest* priority, which\n  * will be at the beginning of the `std::set`.\n  *\n  * @return The obj_id_t of the evicted object. Returns 0 if\n  * the cache is empty.\n  */\n  obj_id_t evict() {\n    if (priority_queue.empty()) {\n      return 0;\n    }\n\n    auto victim_node_it = priority_queue.begin();\n    obj_id_t victim_id = victim_node_it->id;\n    double victim_priority = victim_node_it->priority;\n\n    cache_objects.erase(victim_id);\n    priority_queue.erase(victim_node_it);\n    pri_last_evict = victim_priority;\n\n    return victim_id;\n  }\n};\n```\n", "user": "# Current Program Information\n- Fitness: 0.8508\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness unchanged at 0.8508\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### full_results_json\n```\n{\"score\": 0.8508, \"results\": [{\"cache_name\": \"FullCodeEvolve\", \"cache_size_mb\": 4, \"n_miss\": 1201085, \"n_req\": 3275919, \"miss_ratio\": 0.3666, \"byte_miss_ratio\": 0.634, \"runtime_seconds\": 14.728091}, {\"cache_name\": \"FullCodeEvolve\", \"cache_size_mb\": 45, \"n_miss\": 833986, \"n_req\": 3275919, \"miss_ratio\": 0.2546, \"byte_miss_ratio\": 0.4308, \"runtime_seconds\": 14.728091}, {\"cache_name\": \"FullCodeEvolve\", \"cache_size_mb\": 450, \"n_miss\": 488612, \"n_req\": 3275919, \"miss_ratio\": 0.1492, \"byte_miss_ratio\": 0.2337, \"runtime_seconds\": 14.728091}]}\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 66 lines with 75 lines\n- Metrics: combined_score: 0.8508, miss_ratio_4: 0.3666, miss_ratio_45: 0.2546, miss_ratio_450: 0.1492\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Change 1: Replace 12 lines with 12 lines\nChange 2: Replace 18 lines with 11 lines\n- Metrics: combined_score: 0.8572, miss_ratio_4: 0.3590, miss_ratio_45: 0.2413, miss_ratio_450: 0.1428\n- Outcome: Improvement in all metrics\n\n### Attempt 1\n- Changes: Unknown changes\n- Metrics: combined_score: 0.8572, miss_ratio_4: 0.3590, miss_ratio_45: 0.2413, miss_ratio_450: 0.1428\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.8572)\n```python\n#include <cstdint>\n#include <iomanip>\n#include <iostream>\n#include <set>\n#include <string>\n#include <unordered_map>\n\ntypedef uint64_t obj_id_t;\n\n/**\n * Implements the Greedy-Dual-Size-Frequency (GDSF) eviction policy.\n *\n * This class manages the cache eviction state. It tracks objects,\n * their sizes, and their frequencies to calculate a priority for\n * eviction. It evicts the object with the *lowest* priority.\n *\n * Priority (H-value) is calculated as: L + (Frequency / Size)\n * where 'L' is the priority of the last evicted item.\n */\nclass CacheManager {\nprivate:\n  /**\n   * Node stored in the priority queue (std::set).\n   *\n   * We use std::set as a min-priority queue. It stores nodes\n   * ordered by priority, then by a timestamp as a tie-breaker.\n   */\n  struct PQNode {\n    double priority;\n    uint64_t timestamp; // Tie-breaker, incremented on each access\n    obj_id_t id;\n\n    // Constructor\n    PQNode(double p, uint64_t ts, obj_id_t i)\n        : priority(p), timestamp(ts), id(i) {}\n\n    // Comparison operator for std::set\n    // Orders by priority (lowest first), then timestamp\n    bool operator<(const PQNode &other) const {\n      if (priority != other.priority) {\n        return priority < other.priority;\n      }\n      return timestamp < other.timestamp;\n    }\n  };\n\n  /**\n   * Metadata for each object stored in the cache.\n   *\n   * Stored as the value in the main `cache_objects` map.\n   */\n  struct CacheObject {\n    uint64_t size;\n    uint64_t frequency;\n    // An iterator pointing to this object's entry in the\n    // priority_queue set. This allows for O(log N) removal\n    // during a `find` operation.\n    std::set<PQNode>::iterator pq_iterator;\n  };\n\n  /**\n   * Main lookup map.\n   *\n   * Maps an object's ID to its metadata (size, freq, and\n   * iterator into the priority queue).\n   */\n  std::unordered_map<obj_id_t, CacheObject> cache_objects;\n\n  /**\n   * The priority queue.\n   *\n   * Implemented as an std::set to keep items sorted by priority\n   * and allow for efficient removal from anywhere in the queue.\n   * The item at `priority_queue.begin()` is the eviction victim.\n   */\n  std::set<PQNode> priority_queue;\n\n  /**\n   *  The 'L' value in GDSF.\n   *\n   * This is the priority of the last item that was evicted.\n   * It's used as the base priority for all new and re-prioritized items.\n   */\n  double pri_last_evict = 0.0;\n\n  /**\n   * A simple counter to use as a timestamp for tie-breaking.\n   *\n   * This ensures FIFO-like behavior for items with the same priority.\n   */\n  uint64_t request_counter = 0;\n\n  /**\n   * Helper function to calculate an object's priority (H-value).\n   *\n   * From the original code: pri = L + (freq * 1.0e6 / size)\n   * The 1.0e6 is a scaling factor to keep the (freq/size)\n   * component significant.\n   */\n  double calculate_priority(uint64_t freq, uint64_t size) {\n    if (size == 0) {\n      return pri_last_evict + (double)(freq) * 1.0e6;\n    }\n    return pri_last_evict + (double)(freq) * 1.0e6 / size;\n  }\n\npublic:\n  /**\n   * Default constructor.\n   */\n  CacheManager() = default;\n\n  /**\n   * Finds an object in the cache.\n   *\n   * If the object is found, its frequency is incremented, its\n   * priority is recalculated, and its position in the\n   * priority queue is updated.\n   *\n   * @param obj_id The ID of the object to find.\n   * @return true if the object was found (a hit), false otherwise (a miss).\n   */\n  bool find(obj_id_t obj_id) {\n    auto map_iter = cache_objects.find(obj_id);\n\n    if (map_iter == cache_objects.end()) {\n      return false;\n    }\n\n    CacheObject &obj = map_iter->second;\n    priority_queue.erase(obj.pq_iterator);\n    obj.frequency += 1;\n    double new_pri = calculate_priority(obj.frequency, obj.size);\n\n    PQNode new_node(new_pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    obj.pq_iterator = set_iter;\n\n    return true;\n  }\n\n  /**\n   * Inserts a new object into the cache.\n   *\n   * Assumes this is called after a `find` reported a miss.\n   * If the object already exists, this function will behave\n   * like `find()` and update its priority.\n   *\n   * @param obj_id The ID of the object to insert.\n   * @param obj_size The size of the object (required for GDSF).\n   */\n  void insert(obj_id_t obj_id, uint64_t obj_size) {\n    if (cache_objects.count(obj_id)) {\n      find(obj_id);\n      return;\n    }\n\n    CacheObject new_obj;\n    new_obj.size = obj_size;\n    new_obj.frequency = 1;\n\n    double pri = calculate_priority(new_obj.frequency, new_obj.size);\n    PQNode new_node(pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    new_obj.pq_iterator = set_iter;\n    cache_objects[obj_id] = new_obj;\n  }\n\n  /**\n   * Selects, removes, and returns the victim object to evict.\n   *\n   * The victim is the object with the *lowest* priority, which\n   * will be at the beginning of the `std::set`.\n   *\n   * @return The obj_id_t of the evicted object. Returns 0 if\n   * the cache is empty.\n   */\n  obj_id_t evict() {\n    if (priority_queue.empty()) {\n      return 0;\n    }\n\n    auto victim_node_it = priority_queue.begin();\n    obj_id_t victim_id = victim_node_it->id;\n    double victim_priority = victim_node_it->priority;\n\n    cache_objects.erase(victim_id);\n    priority_queue.erase(victim_node_it);\n    pri_last_evict = victim_priority;\n\n    return victim_id;\n  }\n};\n```\nKey features: Performs well on combined_score (0.8572), Performs well on miss_ratio_4 (0.3590), Performs well on miss_ratio_45 (0.2413), Performs well on miss_ratio_450 (0.1428)\n\n### Program 2 (Score: 0.8572)\n```python\n#include <cstdint>\n#include <unordered_map>\n#include <set>\n\ntypedef uint64_t obj_id_t;\n\nclass CacheManager {\nprivate:\n    // GDSF with frequency aging: track frequency and size for each object.\n    struct CacheObject {\n        uint64_t freq;\n        uint64_t size;\n        uint64_t timestamp;\n        std::set<std::tuple<double, uint64_t, obj_id_t>>::iterator pqit;\n    };\n    // Priority queue node: tuple for easy erase and reinsert\n    // (priority, timestamp, obj_id)\n    std::set<std::tuple<double, uint64_t, obj_id_t>> priority_set;\n    std::unordered_map<obj_id_t, CacheObject> cache_map;\n    uint64_t counter = 0;\n    double last_evict_pri = 0.0;\n\n    // Slightly decrease freq on every eviction to \"age\" frequency counts\n    // Remove frequency aging for simplicity and to boost recency bias\n    // This avoids global rescoring that can cause massive churn.\n    void age_frequencies() {\n        // No-op: remove explicit frequency aging\n    }\n\n    double calc_pri(uint64_t freq, uint64_t size) {\n        // Remove recency bonus to make scoring strictly GDSF\n        if (size == 0) return last_evict_pri + freq * 1e6;\n        return last_evict_pri + double(freq) * 1e6 / size;\n    }\n\npublic:\n    bool find(obj_id_t obj_id) {\n        auto it = cache_map.find(obj_id);\n        if (it == cache_map.end()) return false;\n        // Erase from set using iterator (O(log N))\n        priority_set.erase(it->second.pqit);\n        it->second.freq += 1;\n        it->second.timestamp = ++counter;\n        double new_pri = calc_pri(it->second.freq, it->second.size);\n        auto pqit = priority_set.insert({new_pri, it->second.timestamp, obj_id}).first;\n        it->second.pqit = pqit;\n        return true;\n    }\n\n    void insert(obj_id_t obj_id, uint64_t obj_size) {\n        auto it = cache_map.find(obj_id);\n        if (it != cache_map.end()) {\n            find(obj_id);\n            return;\n        }\n        uint64_t freq = 1;\n        uint64_t ts = ++counter;\n        double pri = calc_pri(freq, obj_size);\n        auto pqit = priority_set.insert({pri, ts, obj_id}).first;\n        cache_map[obj_id] = {freq, obj_size, ts, pqit};\n    }\n\n    obj_id_t evict() {\n        if (priority_set.empty()) return 0;\n        auto it = priority_set.begin();\n        obj_id_t victim = std::get<2>(*it);\n        last_evict_pri = std::get<0>(*it);\n        priority_set.erase(it);\n        cache_map.erase(victim);\n        // No global frequency aging or rescoring\n        return victim;\n    }\n};\n```\nKey features: Performs well on combined_score (0.8572), Performs well on miss_ratio_4 (0.3590), Performs well on miss_ratio_45 (0.2413), Performs well on miss_ratio_450 (0.1428)\n\n### Program 3 (Score: 0.8508)\n```python\n#include <cstdint>\n#include <unordered_map>\n#include <set>\n\ntypedef uint64_t obj_id_t;\n\n// GDSF-inspired hybrid: frequency/size, small object bias, recency tiebreak\nclass CacheManager {\nprivate:\n    struct Node {\n        double priority;\n        uint64_t timestamp;\n        uint64_t freq;\n        uint64_t size;\n        obj_id_t id;\n        Node(double p, uint64_t ts, uint64_t f, uint64_t s, obj_id_t i)\n            : priority(p), timestamp(ts), freq(f), size(s), id(i) {}\n        bool operator<(const Node &o) const {\n            if (priority != o.priority) return priority < o.priority;\n            return timestamp < o.timestamp;\n        }\n    };\n\n    std::set<Node> pq;\n    std::unordered_map<obj_id_t, std::set<Node>::iterator> obj2it;\n    std::unordered_map<obj_id_t, uint64_t> obj2size;\n    double last_evict_pri = 0.0;\n    uint64_t counter = 0;\n\n    double calc_priority(uint64_t freq, uint64_t size) {\n        // GDSF: L + freq*1e6/size, favor smalls and recency\n        double small_bonus = (size <= 8) ? 1.0 : 0.0;\n        if (size == 0) return last_evict_pri + (freq + small_bonus) * 1e6 + counter * 1e-4;\n        return last_evict_pri + (freq + small_bonus) * 1e6 / size + counter * 1e-4;\n    }\n\npublic:\n    bool find(obj_id_t obj_id) {\n        auto it = obj2it.find(obj_id);\n        if (it == obj2it.end()) return false;\n        Node node = *(it->second);\n        pq.erase(it->second);\n        node.freq += (node.size <= 8) ? 2 : 1; // boost small objects' freq further on hit\n        node.timestamp = ++counter;\n        node.priority = calc_priority(node.freq, node.size);\n        auto iter = pq.insert(node).first;\n        obj2it[obj_id] = iter;\n        obj2size[obj_id] = node.size;\n        return true;\n    }\n\n    void insert(obj_id_t obj_id, uint64_t obj_size) {\n        auto it = obj2it.find(obj_id);\n        if (it != obj2it.end()) {\n            find(obj_id);\n            return;\n        }\n        uint64_t init_freq = (obj_size <= 8) ? 2 : 1; // small objects start hotter\n        Node node(calc_priority(init_freq, obj_size), ++counter, init_freq, obj_size, obj_id);\n        auto iter = pq.insert(node).first;\n        obj2it[obj_id] = iter;\n        obj2size[obj_id] = obj_size;\n    }\n\n    obj_id_t evict() {\n        if (pq.empty()) return 0;\n        auto it = pq.begin();\n        obj_id_t victim = it->id;\n        last_evict_pri = it->priority;\n        pq.erase(it);\n        obj2it.erase(victim);\n        obj2size.erase(victim);\n        return victim;\n    }\n};\n```\nKey features: Performs well on combined_score (0.8508), Performs well on miss_ratio_4 (0.3666), Performs well on miss_ratio_45 (0.2546), Performs well on miss_ratio_450 (0.1492)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.8508)\n```python\n#include <cstdint>\n#include <iomanip>\n#include <iostream>\n#include <set>\n#include <string>\n#include <unordered_map>\n\ntypedef uint64_t obj_id_t;\n\n/**\n * Implements the Greedy-Dual-Size-Frequency (GDSF) eviction policy.\n *\n * This class manages the cache eviction state. It tracks objects,\n * their sizes, and their frequencies to calculate a priority for\n * eviction. It evicts the object with the *lowest* priority.\n *\n * Priority (H-value) is calculated as: L + (Frequency / Size)\n * where 'L' is the priority of the last evicted item.\n */\nclass CacheManager {\nprivate:\n  /**\n   * Node stored in the priority queue (std::set).\n   *\n   * We use std::set as a min-priority queue. It stores nodes\n   * ordered by priority, then by a timestamp as a tie-breaker.\n   */\n  struct PQNode {\n    double priority;\n    uint64_t timestamp; // Tie-breaker, incremented on each access\n    obj_id_t id;\n\n    // Constructor\n    PQNode(double p, uint64_t ts, obj_id_t i)\n        : priority(p), timestamp(ts), id(i) {}\n\n    // Comparison operator for std::set\n    // Orders by priority (lowest first), then timestamp\n    bool operator<(const PQNode &other) const {\n      if (priority != other.priority) {\n        return priority < other.priority;\n      }\n      return timestamp < other.timestamp;\n    }\n  };\n\n  /**\n   * Metadata for each object stored in the cache.\n   *\n   * Stored as the value in the main `cache_objects` map.\n   */\n  struct CacheObject {\n    uint64_t size;\n    uint64_t frequency;\n    // An iterator pointing to this object's entry in the\n    // priority_queue set. This allows for O(log N) removal\n    // during a `find` operation.\n    std::set<PQNode>::iterator pq_iterator;\n  };\n\n  /**\n   * Main lookup map.\n   *\n   * Maps an object's ID to its metadata (size, freq, and\n   * iterator into the priority queue).\n   */\n  std::unordered_map<obj_id_t, CacheObject> cache_objects;\n\n  /**\n   * The priority queue.\n   *\n   * Implemented as an std::set to keep items sorted by priority\n   * and allow for efficient removal from anywhere in the queue.\n   * The item at `priority_queue.begin()` is the eviction victim.\n   */\n  std::set<PQNode> priority_queue;\n\n  /**\n   *  The 'L' value in GDSF.\n   *\n   * This is the priority of the last item that was evicted.\n   * It's used as the base priority for all new and re-prioritized items.\n   */\n  double pri_last_evict = 0.0;\n\n  /**\n   * A simple counter to use as a timestamp for tie-breaking.\n   *\n   * This ensures FIFO-like behavior for items with the same priority.\n   */\n  uint64_t request_counter = 0;\n\n  /**\n   * Helper function to calculate an object's priority (H-value).\n   *\n   * From the original code: pri = L + (freq * 1.0e6 / size)\n   * The 1.0e6 is a scaling factor to keep the (freq/size)\n   * component significant.\n   */\n  // Boost small objects that are accessed frequently, but add slight recency bonus\n  double calculate_priority(uint64_t freq, uint64_t size) {\n    if (size == 0) {\n      return pri_last_evict + (double)(freq) * 1.0e6;\n    }\n    // Add small recency term (scaled by 1e-4) to break ties in favor of newer objects\n    return pri_last_evict + (double)(freq) * 1.0e6 / size + (request_counter * 1e-4);\n  }\n\npublic:\n  /**\n   * Default constructor.\n   */\n  CacheManager() = default;\n\n  /**\n   * Finds an object in the cache.\n   *\n   * If the object is found, its frequency is incremented, its\n   * priority is recalculated, and its position in the\n   * priority queue is updated.\n   *\n   * @param obj_id The ID of the object to find.\n   * @return true if the object was found (a hit), false otherwise (a miss).\n   */\n  bool find(obj_id_t obj_id) {\n    auto map_iter = cache_objects.find(obj_id);\n\n    if (map_iter == cache_objects.end()) {\n      return false;\n    }\n\n    CacheObject &obj = map_iter->second;\n    priority_queue.erase(obj.pq_iterator);\n    obj.frequency += 1;\n    // Upon hit, mildly favor very small objects by giving a slightly bigger frequency increase\n    if (obj.size <= 8) obj.frequency += 1;\n    double new_pri = calculate_priority(obj.frequency, obj.size);\n\n    PQNode new_node(new_pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    obj.pq_iterator = set_iter;\n\n    return true;\n  }\n\n  /**\n   * Inserts a new object into the cache.\n   *\n   * Assumes this is called after a `find` reported a miss.\n   * If the object already exists, this function will behave\n   * like `find()` and update its priority.\n   *\n   * @param obj_id The ID of the object to insert.\n   * @param obj_size The size of the object (required for GDSF).\n   */\n  void insert(obj_id_t obj_id, uint64_t obj_size) {\n    if (cache_objects.count(obj_id)) {\n      find(obj_id);\n      return;\n    }\n\n    CacheObject new_obj;\n    new_obj.size = obj_size;\n    // Slightly prefer very small objects on insert by giving them higher initial frequency\n    new_obj.frequency = (obj_size <= 8) ? 2 : 1;\n\n    double pri = calculate_priority(new_obj.frequency, new_obj.size);\n    PQNode new_node(pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    new_obj.pq_iterator = set_iter;\n    cache_objects[obj_id] = new_obj;\n  }\n\n  /**\n   * Selects, removes, and returns the victim object to evict.\n   *\n   * The victim is the object with the *lowest* priority, which\n   * will be at the beginning of the `std::set`.\n   *\n   * @return The obj_id_t of the evicted object. Returns 0 if\n   * the cache is empty.\n   */\n  obj_id_t evict() {\n    if (priority_queue.empty()) {\n      return 0;\n    }\n\n    auto victim_node_it = priority_queue.begin();\n    obj_id_t victim_id = victim_node_it->id;\n    double victim_priority = victim_node_it->priority;\n\n    cache_objects.erase(victim_id);\n    priority_queue.erase(victim_node_it);\n    pri_last_evict = victim_priority;\n\n    return victim_id;\n  }\n};\n```\nKey features: Alternative approach to combined_score, Alternative approach to miss_ratio_4\n\n### Program D2 (Score: 0.8508)\n```python\n#include <cstdint>\n#include <unordered_map>\n#include <set>\n\ntypedef uint64_t obj_id_t;\n\nclass CacheManager {\nprivate:\n    // GDSF with frequency aging: track frequency and size for each object.\n    struct CacheObject {\n        uint64_t freq;\n        uint64_t size;\n        uint64_t timestamp;\n        std::set<std::tuple<double, uint64_t, obj_id_t>>::iterator pqit;\n    };\n    // Priority queue node: tuple for easy erase and reinsert\n    // (priority, timestamp, obj_id)\n    std::set<std::tuple<double, uint64_t, obj_id_t>> priority_set;\n    std::unordered_map<obj_id_t, CacheObject> cache_map;\n    uint64_t counter = 0;\n    double last_evict_pri = 0.0;\n\n    // Slightly decrease freq on every eviction to \"age\" frequency counts\n    // Remove frequency aging for simplicity and to boost recency bias\n    // This avoids global rescoring that can cause massive churn.\n    void age_frequencies() {\n        // No-op: remove explicit frequency aging\n    }\n\n    double calc_pri(uint64_t freq, uint64_t size) {\n        // Mildly boost tiny objects and add slight recency tiebreak\n        double small_bonus = (size <= 8) ? 1.0 : 0.0;\n        if (size == 0) return last_evict_pri + (freq + small_bonus) * 1e6 + counter * 1e-4;\n        return last_evict_pri + (double(freq) + small_bonus) * 1e6 / size + counter * 1e-4;\n    }\n\npublic:\n    bool find(obj_id_t obj_id) {\n        auto it = cache_map.find(obj_id);\n        if (it == cache_map.end()) return false;\n        // Erase from set using iterator (O(log N))\n        priority_set.erase(it->second.pqit);\n        // Give tiny objects a hotter frequency bump on hit\n        if (it->second.size <= 8)\n            it->second.freq += 2;\n        else\n            it->second.freq += 1;\n        it->second.timestamp = ++counter;\n        double new_pri = calc_pri(it->second.freq, it->second.size);\n        auto pqit = priority_set.insert({new_pri, it->second.timestamp, obj_id}).first;\n        it->second.pqit = pqit;\n        return true;\n    }\n\n    void insert(obj_id_t obj_id, uint64_t obj_size) {\n        auto it = cache_map.find(obj_id);\n        if (it != cache_map.end()) {\n            find(obj_id);\n            return;\n        }\n        // Slightly favor tiny objects on insert\n        uint64_t freq = (obj_size <= 8) ? 2 : 1;\n        uint64_t ts = ++counter;\n        double pri = calc_pri(freq, obj_size);\n        auto pqit = priority_set.insert({pri, ts, obj_id}).first;\n        cache_map[obj_id] = {freq, obj_size, ts, pqit};\n    }\n\n    obj_id_t evict() {\n        if (priority_set.empty()) return 0;\n        auto it = priority_set.begin();\n        obj_id_t victim = std::get<2>(*it);\n        last_evict_pri = std::get<0>(*it);\n        priority_set.erase(it);\n        cache_map.erase(victim);\n        // No global frequency aging or rescoring\n        return victim;\n    }\n};\n```\nKey features: Alternative approach to combined_score, Alternative approach to miss_ratio_4\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: -inf, Type: Exploratory)\n```python\n#include <cstdint>\n#include <unordered_map>\n#include <set>\n\ntypedef uint64_t obj_id_t;\n\n// LFU+Size-Aware: Uses frequency, but for ties, prefers to evict LARGER objects (so we keep small hot objects).\n// This variant adds a \"recently evicted priority\" (GDSF L value) to the mix for more adaptation to changing workloads.\nclass CacheManager {\nprivate:\n    struct LFUNode {\n        double priority;   // Priority value for eviction ordering (incorporates freq and size with L aging)\n        uint64_t timestamp;\n        uint64_t freq;\n        uint64_t size;\n        obj_id_t obj_id;\n        LFUNode(double pri, uint64_t ts, uint64_t f, uint64_t s, obj_id_t id)\n            : priority(pri), timestamp(ts), freq(f), size(s), obj_id(id) {}\n        // Lower priority first. Break ties by timestamp, then by obj_id.\n        bool operator<(const LFUNode &o) const {\n            if (priority != o.priority) return priority < o.priority;\n            if (timestamp != o.timestamp) return timestamp < o.timestamp;\n            return obj_id < o.obj_id;\n        }\n    };\n\n    std::unordered_map<obj_id_t, std::set<LFUNode>::iterator> obj2iter;\n    std::unordered_map<obj_id_t, uint64_t> obj2size;\n    std::unordered_map<obj_id_t, uint64_t> obj2freq;\n    std::set<LFUNode> lfu_set;\n    uint64_t time_counter = 0;\n    double last_evict_pri = 0.0;\n\n    double calc_priority(uint64_t freq, uint64_t size) {\n        // GDSF-inspired: L + freq / size (scaled)\n        if (size == 0) return last_evict_pri + freq * 1e6;\n        return last_evict_pri + (double(freq) * 1e6 / double(size));\n    }\n\npublic:\n    bool find(obj_id_t obj_id) {\n        auto it = obj2iter.find(obj_id);\n        if (it == obj2iter.end()) return false;\n        auto node = *(it->second);\n        lfu_set.erase(it->second);\n\n        uint64_t new_freq = node.freq + 1;\n        obj2freq[obj_id] = new_freq;\n        double new_pri = calc_priority(new_freq, node.size);\n        auto iter = lfu_set.insert(LFUNode(new_pri, ++time_counter, new_freq, node.size, node.obj_id)).first;\n        obj2iter[obj_id] = iter;\n\n        // Touch size on access in case \"insert\" was called with a new size value\n        obj2size[obj_id] = node.size;\n        return true;\n    }\n\n    void insert(obj_id_t obj_id, uint64_t obj_size) {\n        auto it = obj2iter.find(obj_id);\n        if (it != obj2iter.end()) {\n            // Update to latest known size\n            uint64_t cur_freq = obj2freq[obj_id];\n            obj2size[obj_id] = obj_size;\n            lfu_set.erase(it->second);\n            double pri = calc_priority(cur_freq, obj_size);\n            auto iter = lfu_set.insert(LFUNode(pri, ++time_counter, cur_freq, obj_size, obj_id)).first;\n            obj2iter[obj_id] = iter;\n            return;\n        }\n        obj2size[obj_id] = obj_size;\n        obj2freq[obj_id] = 1;\n        double pri = calc_priority(1, obj_size);\n        LFUNode node(pri, ++time_counter, 1, obj_size, obj_id);\n        auto iter = lfu_set.insert(node).first;\n        obj2iter[obj_id] = iter;\n    }\n\n    obj_id_t evict() {\n        if (lfu_set.empty()) return 0;\n        auto it = lfu_set.begin();\n        obj_id_t victim = it->obj_id;\n        last_evict_pri = it->priority;\n        lfu_set.erase(it);\n        obj2iter.erase(victim);\n        obj2size.erase(victim);\n        obj2freq.erase(victim);\n\n        // On eviction, slightly decay all remaining frequencies to \"age out\" stale objects\n        if (!lfu_set.empty()) {\n            std::vector<std::pair<obj_id_t, std::set<LFUNode>::iterator>> updates;\n            for (auto iter = lfu_set.begin(); iter != lfu_set.end(); ++iter) {\n                if (iter->freq > 1) {\n                    LFUNode n = *iter;\n                    lfu_set.erase(iter);\n                    n.freq = (n.freq * 7) / 8; // Decay by 1/8 (so active items maintain advantage, but old stale ones don't grow unbounded)\n                    if (n.freq == 0) n.freq = 1;\n                    n.priority = calc_priority(n.freq, n.size);\n                    auto newit = lfu_set.insert(n).first;\n                    obj2iter[n.obj_id] = newit;\n                    obj2freq[n.obj_id] = n.freq;\n                    // Do NOT erase/update obj2size here\n                    break; // Only decay one (most stale) on each eviction for performance\n                }\n            }\n        }\n        return victim;\n    }\n};\n```\nUnique approach: Alternative combined_score approach, Comprehensive implementation\n\n### Inspiration 2 (Score: -inf, Type: Exploratory)\n```python\n#include <cstdint>\n#include <unordered_map>\n#include <set>\n\ntypedef uint64_t obj_id_t;\n\n// GDSF-inspired hybrid: frequency/size, small object bias, recency tiebreak\nclass CacheManager {\nprivate:\n    struct Node {\n        double priority;\n        uint64_t timestamp;\n        uint64_t freq;\n        uint64_t size;\n        obj_id_t id;\n        Node(double p, uint64_t ts, uint64_t f, uint64_t s, obj_id_t i)\n            : priority(p), timestamp(ts), freq(f), size(s), id(i) {}\n        bool operator<(const Node &o) const {\n            if (priority != o.priority) return priority < o.priority;\n            return timestamp < o.timestamp;\n        }\n    };\n\n    std::set<Node> pq;\n    std::unordered_map<obj_id_t, std::set<Node>::iterator> obj2it;\n    std::unordered_map<obj_id_t, uint64_t> obj2size;\n    double last_evict_pri = 0.0;\n    uint64_t counter = 0;\n\n    double calc_priority(uint64_t freq, uint64_t size) {\n        // GDSF: L + freq*1e6/size, favor smalls and recency\n        // Add a mild \"age\" factor to frequency (decay by 10% on each eviction)\n        // and a slightly stronger small object bonus.\n        double small_bonus = (size <= 8) ? 2.0 : 0.0;\n        if (size == 0) return last_evict_pri + (freq + small_bonus) * 1e6 + counter * 1e-4;\n        return last_evict_pri + (freq + small_bonus) * 1e6 / size + counter * 1e-4;\n    }\n\npublic:\n    bool find(obj_id_t obj_id) {\n        auto it = obj2it.find(obj_id);\n        if (it == obj2it.end()) return false;\n        Node node = *(it->second);\n        pq.erase(it->second);\n        node.freq += (node.size <= 8) ? 2 : 1; // boost small objects' freq further on hit\n        node.timestamp = ++counter;\n        node.priority = calc_priority(node.freq, node.size);\n        auto iter = pq.insert(node).first;\n        obj2it[obj_id] = iter;\n        obj2size[obj_id] = node.size;\n        return true;\n    }\n\n    void insert(obj_id_t obj_id, uint64_t obj_size) {\n        auto it = obj2it.find(obj_id);\n        if (it != obj2it.end()) {\n            find(obj_id);\n            return;\n        }\n        uint64_t init_freq = (obj_size <= 8) ? 2 : 1; // small objects start hotter\n        Node node(calc_priority(init_freq, obj_size), ++counter, init_freq, obj_size, obj_id);\n        auto iter = pq.insert(node).first;\n        obj2it[obj_id] = iter;\n        obj2size[obj_id] = obj_size;\n    }\n\n    obj_id_t evict() {\n        if (pq.empty()) return 0;\n        auto it = pq.begin();\n        obj_id_t victim = it->id;\n        last_evict_pri = it->priority;\n\n        // Decay the frequency of all objects except the evicted one,\n        // but do not let frequency fall below 1.\n        std::vector<std::pair<obj_id_t, Node>> updates;\n        for (auto oit = pq.begin(); oit != pq.end(); ++oit) {\n            if (oit->id == victim) continue;\n            Node n = *oit;\n            uint64_t new_freq = n.freq > 1 ? uint64_t(n.freq * 0.9) : 1;\n            if (new_freq != n.freq) {\n                n.freq = new_freq;\n                n.priority = calc_priority(n.freq, n.size);\n                updates.emplace_back(n.id, n);\n            }\n        }\n        // Apply updates: remove and re-insert with new priority\n        for (const auto& pr : updates) {\n            auto sit = obj2it[pr.first];\n            pq.erase(sit);\n            auto iter = pq.insert(pr.second).first;\n            obj2it[pr.first] = iter;\n        }\n\n        pq.erase(it);\n        obj2it.erase(victim);\n        obj2size.erase(victim);\n        return victim;\n    }\n};\n```\nUnique approach: Modification: Change 1: Replace 6 lines with 8 lines\nChange 2: Replace 10 lines with 32 lines, Alternative combined_score approach, Comprehensive implementation\n\n### Inspiration 3 (Score: -inf, Type: Exploratory)\n```python\n#include <cstdint>\n#include <unordered_map>\n#include <set>\n\ntypedef uint64_t obj_id_t;\n\n// GDSF-inspired hybrid: frequency/size, small object bias, recency tiebreak\nclass CacheManager {\nprivate:\n    struct Node {\n        double priority;\n        uint64_t timestamp;\n        uint64_t freq;\n        uint64_t size;\n        obj_id_t id;\n        Node(double p, uint64_t ts, uint64_t f, uint64_t s, obj_id_t i)\n            : priority(p), timestamp(ts), freq(f), size(s), id(i) {}\n        bool operator<(const Node &o) const {\n            if (priority != o.priority) return priority < o.priority;\n            return timestamp < o.timestamp;\n        }\n    };\n\n    std::set<Node> pq;\n    std::unordered_map<obj_id_t, std::set<Node>::iterator> obj2it;\n    std::unordered_map<obj_id_t, uint64_t> obj2size;\n    double last_evict_pri = 0.0;\n    uint64_t counter = 0;\n\n    double calc_priority(uint64_t freq, uint64_t size) {\n        // GDSF: L + freq*1e6/size, favor smalls and recency\n        // Add a more aggressive bias to very small objects, and apply sublinear frequency increment\n        double small_bonus = (size <= 8) ? 3.0 : (size <= 64) ? 1.0 : 0.0;\n        double freq_term = pow(double(freq), 0.85); // Sublinear freq growth\n        if (size == 0) return last_evict_pri + (freq_term + small_bonus) * 1e6 + counter * 1e-4;\n        return last_evict_pri + (freq_term + small_bonus) * 1e6 / size + counter * 1e-4;\n    }\n\npublic:\n    bool find(obj_id_t obj_id) {\n        auto it = obj2it.find(obj_id);\n        if (it == obj2it.end()) return false;\n        Node node = *(it->second);\n        pq.erase(it->second);\n        // Boost small objects more on hit, and use higher bonus for tiny objects\n        node.freq += (node.size <= 8) ? 3 : (node.size <= 64) ? 2 : 1;\n        node.timestamp = ++counter;\n        node.priority = calc_priority(node.freq, node.size);\n        auto iter = pq.insert(node).first;\n        obj2it[obj_id] = iter;\n        obj2size[obj_id] = node.size;\n        return true;\n    }\n\n    void insert(obj_id_t obj_id, uint64_t obj_size) {\n        auto it = obj2it.find(obj_id);\n        if (it != obj2it.end()) {\n            find(obj_id);\n            return;\n        }\n        // Tiny objects start even hotter, small objects start modestly hot\n        uint64_t init_freq = (obj_size <= 8) ? 3 : (obj_size <= 64) ? 2 : 1;\n        Node node(calc_priority(init_freq, obj_size), ++counter, init_freq, obj_size, obj_id);\n        auto iter = pq.insert(node).first;\n        obj2it[obj_id] = iter;\n        obj2size[obj_id] = obj_size;\n    }\n\n    obj_id_t evict() {\n        if (pq.empty()) return 0;\n        auto it = pq.begin();\n        obj_id_t victim = it->id;\n        last_evict_pri = it->priority;\n        pq.erase(it);\n        obj2it.erase(victim);\n        obj2size.erase(victim);\n        return victim;\n    }\n};\n```\nUnique approach: Alternative combined_score approach, Comprehensive implementation\n\n# Current Program\n```python\n#include <cstdint>\n#include <unordered_map>\n#include <set>\n\ntypedef uint64_t obj_id_t;\n\nclass CacheManager {\nprivate:\n    // GDSF with frequency aging: track frequency and size for each object.\n    struct CacheObject {\n        uint64_t freq;\n        uint64_t size;\n        uint64_t timestamp;\n        std::set<std::tuple<double, uint64_t, obj_id_t>>::iterator pqit;\n    };\n    // Priority queue node: tuple for easy erase and reinsert\n    // (priority, timestamp, obj_id)\n    std::set<std::tuple<double, uint64_t, obj_id_t>> priority_set;\n    std::unordered_map<obj_id_t, CacheObject> cache_map;\n    uint64_t counter = 0;\n    double last_evict_pri = 0.0;\n\n    // Slightly decrease freq on every eviction to \"age\" frequency counts\n    // Remove frequency aging for simplicity and to boost recency bias\n    // This avoids global rescoring that can cause massive churn.\n    void age_frequencies() {\n        // No-op: remove explicit frequency aging\n    }\n\n    double calc_pri(uint64_t freq, uint64_t size) {\n        // Mildly boost tiny objects and add slight recency tiebreak\n        double small_bonus = (size <= 8) ? 1.0 : 0.0;\n        if (size == 0) return last_evict_pri + (freq + small_bonus) * 1e6 + counter * 1e-4;\n        return last_evict_pri + (double(freq) + small_bonus) * 1e6 / size + counter * 1e-4;\n    }\n\npublic:\n    bool find(obj_id_t obj_id) {\n        auto it = cache_map.find(obj_id);\n        if (it == cache_map.end()) return false;\n        // Erase from set using iterator (O(log N))\n        priority_set.erase(it->second.pqit);\n        // Give tiny objects a hotter frequency bump on hit\n        if (it->second.size <= 8)\n            it->second.freq += 2;\n        else\n            it->second.freq += 1;\n        it->second.timestamp = ++counter;\n        double new_pri = calc_pri(it->second.freq, it->second.size);\n        auto pqit = priority_set.insert({new_pri, it->second.timestamp, obj_id}).first;\n        it->second.pqit = pqit;\n        return true;\n    }\n\n    void insert(obj_id_t obj_id, uint64_t obj_size) {\n        auto it = cache_map.find(obj_id);\n        if (it != cache_map.end()) {\n            find(obj_id);\n            return;\n        }\n        // Slightly favor tiny objects on insert\n        uint64_t freq = (obj_size <= 8) ? 2 : 1;\n        uint64_t ts = ++counter;\n        double pri = calc_pri(freq, obj_size);\n        auto pqit = priority_set.insert({pri, ts, obj_id}).first;\n        cache_map[obj_id] = {freq, obj_size, ts, pqit};\n    }\n\n    obj_id_t evict() {\n        if (priority_set.empty()) return 0;\n        auto it = priority_set.begin();\n        obj_id_t victim = std::get<2>(*it);\n        last_evict_pri = std::get<0>(*it);\n        priority_set.erase(it);\n        cache_map.erase(victim);\n        // No global frequency aging or rescoring\n        return victim;\n    }\n};\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["<<<<<<< SEARCH\n    double calc_pri(uint64_t freq, uint64_t size) {\n        // Mildly boost tiny objects and add slight recency tiebreak\n        double small_bonus = (size <= 8) ? 1.0 : 0.0;\n        if (size == 0) return last_evict_pri + (freq + small_bonus) * 1e6 + counter * 1e-4;\n        return last_evict_pri + (double(freq) + small_bonus) * 1e6 / size + counter * 1e-4;\n    }\n=======\n    double calc_pri(uint64_t freq, uint64_t size) {\n        // More aggressively boost tiny objects, sublinear freq, stronger recency\n        double small_bonus = (size <= 8) ? 3.0 : (size <= 64) ? 1.0 : 0.0;\n        double freq_term = pow(double(freq), 0.85); // sublinear frequency scaling\n        if (size == 0) return last_evict_pri + (freq_term + small_bonus) * 1e6 + counter * 1e-3;\n        return last_evict_pri + (freq_term + small_bonus) * 1e6 / size + counter * 1e-3;\n    }\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\n    bool find(obj_id_t obj_id) {\n        auto it = cache_map.find(obj_id);\n        if (it == cache_map.end()) return false;\n        // Erase from set using iterator (O(log N))\n        priority_set.erase(it->second.pqit);\n        // Give tiny objects a hotter frequency bump on hit\n        if (it->second.size <= 8)\n            it->second.freq += 2;\n        else\n            it->second.freq += 1;\n        it->second.timestamp = ++counter;\n        double new_pri = calc_pri(it->second.freq, it->second.size);\n        auto pqit = priority_set.insert({new_pri, it->second.timestamp, obj_id}).first;\n        it->second.pqit = pqit;\n        return true;\n    }\n=======\n    bool find(obj_id_t obj_id) {\n        auto it = cache_map.find(obj_id);\n        if (it == cache_map.end()) return false;\n        // Erase from set using iterator (O(log N))\n        priority_set.erase(it->second.pqit);\n        // More aggressive tiny object bump, sublinear freq increment\n        if (it->second.size <= 8)\n            it->second.freq += 3;\n        else if (it->second.size <= 64)\n            it->second.freq += 2;\n        else\n            it->second.freq += 1;\n        it->second.timestamp = ++counter;\n        double new_pri = calc_pri(it->second.freq, it->second.size);\n        auto pqit = priority_set.insert({new_pri, it->second.timestamp, obj_id}).first;\n        it->second.pqit = pqit;\n        return true;\n    }\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\n    void insert(obj_id_t obj_id, uint64_t obj_size) {\n        auto it = cache_map.find(obj_id);\n        if (it != cache_map.end()) {\n            find(obj_id);\n            return;\n        }\n        // Slightly favor tiny objects on insert\n        uint64_t freq = (obj_size <= 8) ? 2 : 1;\n        uint64_t ts = ++counter;\n        double pri = calc_pri(freq, obj_size);\n        auto pqit = priority_set.insert({pri, ts, obj_id}).first;\n        cache_map[obj_id] = {freq, obj_size, ts, pqit};\n    }\n=======\n    void insert(obj_id_t obj_id, uint64_t obj_size) {\n        auto it = cache_map.find(obj_id);\n        if (it != cache_map.end()) {\n            find(obj_id);\n            return;\n        }\n        // Aggressively favor very small and small objects on insert\n        uint64_t freq = (obj_size <= 8) ? 3 : (obj_size <= 64) ? 2 : 1;\n        uint64_t ts = ++counter;\n        double pri = calc_pri(freq, obj_size);\n        auto pqit = priority_set.insert({pri, ts, obj_id}).first;\n        cache_map[obj_id] = {freq, obj_size, ts, pqit};\n    }\n>>>>>>> REPLACE"]}}, "artifacts_json": "{\"status\": \"SKIPPED - Build/Run lock busy\"}", "artifact_dir": null, "embedding": null}