{"id": "28a3ae69-f1a6-4fc9-817b-cb3753a17d5a", "code": "#include <cstdint>\n#include <iomanip>\n#include <iostream>\n#include <set>\n#include <string>\n#include <unordered_map>\n\ntypedef uint64_t obj_id_t;\n\n/**\n * Implements the Greedy-Dual-Size-Frequency (GDSF) eviction policy.\n *\n * This class manages the cache eviction state. It tracks objects,\n * their sizes, and their frequencies to calculate a priority for\n * eviction. It evicts the object with the *lowest* priority.\n *\n * Priority (H-value) is calculated as: L + (Frequency / Size)\n * where 'L' is the priority of the last evicted item.\n */\nclass CacheManager {\nprivate:\n  /**\n   * Node stored in the priority queue (std::set).\n   *\n   * We use std::set as a min-priority queue. It stores nodes\n   * ordered by priority, then by a timestamp as a tie-breaker.\n   */\n  struct PQNode {\n    double priority;\n    uint64_t timestamp; // Tie-breaker, incremented on each access\n    obj_id_t id;\n\n    // Constructor\n    PQNode(double p, uint64_t ts, obj_id_t i)\n        : priority(p), timestamp(ts), id(i) {}\n\n    // Comparison operator for std::set\n    // Orders by priority (lowest first), then timestamp\n    bool operator<(const PQNode &other) const {\n      if (priority != other.priority) {\n        return priority < other.priority;\n      }\n      return timestamp < other.timestamp;\n    }\n  };\n\n  /**\n   * Metadata for each object stored in the cache.\n   *\n   * Stored as the value in the main `cache_objects` map.\n   */\n  struct CacheObject {\n    uint64_t size;\n    uint64_t frequency;\n    // An iterator pointing to this object's entry in the\n    // priority_queue set. This allows for O(log N) removal\n    // during a `find` operation.\n    std::set<PQNode>::iterator pq_iterator;\n  };\n\n  /**\n   * Main lookup map.\n   *\n   * Maps an object's ID to its metadata (size, freq, and\n   * iterator into the priority queue).\n   */\n  std::unordered_map<obj_id_t, CacheObject> cache_objects;\n\n  /**\n   * The priority queue.\n   *\n   * Implemented as an std::set to keep items sorted by priority\n   * and allow for efficient removal from anywhere in the queue.\n   * The item at `priority_queue.begin()` is the eviction victim.\n   */\n  std::set<PQNode> priority_queue;\n\n  /**\n   *  The 'L' value in GDSF.\n   *\n   * This is the priority of the last item that was evicted.\n   * It's used as the base priority for all new and re-prioritized items.\n   */\n  double pri_last_evict = 0.0;\n\n  /**\n   * A simple counter to use as a timestamp for tie-breaking.\n   *\n   * This ensures FIFO-like behavior for items with the same priority.\n   */\n  uint64_t request_counter = 0;\n\n  /**\n   * Helper function to calculate an object's priority (H-value).\n   *\n   * From the original code: pri = L + (freq * 1.0e6 / size)\n   * The 1.0e6 is a scaling factor to keep the (freq/size)\n   * component significant.\n   */\n  // Reduce scaling factor from 1.0e6 to 1.0e5 to minimize domination of frequency/size over recency\n  double calculate_priority(uint64_t freq, uint64_t size) {\n    if (size == 0) {\n      return pri_last_evict + (double)(freq) * 1.0e5;\n    }\n    return pri_last_evict + (double)(freq) * 1.0e5 / size;\n  }\n\npublic:\n  /**\n   * Default constructor.\n   */\n  CacheManager() = default;\n\n  /**\n   * Finds an object in the cache.\n   *\n   * If the object is found, its frequency is incremented, its\n   * priority is recalculated, and its position in the\n   * priority queue is updated.\n   *\n   * @param obj_id The ID of the object to find.\n   * @return true if the object was found (a hit), false otherwise (a miss).\n   */\n  bool find(obj_id_t obj_id) {\n    auto map_iter = cache_objects.find(obj_id);\n\n    if (map_iter == cache_objects.end()) {\n      return false;\n    }\n\n    CacheObject &obj = map_iter->second;\n    priority_queue.erase(obj.pq_iterator);\n    obj.frequency += 1;\n    double new_pri = calculate_priority(obj.frequency, obj.size);\n\n    PQNode new_node(new_pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    obj.pq_iterator = set_iter;\n\n    return true;\n  }\n\n  /**\n   * Inserts a new object into the cache.\n   *\n   * Assumes this is called after a `find` reported a miss.\n   * If the object already exists, this function will behave\n   * like `find()` and update its priority.\n   *\n   * @param obj_id The ID of the object to insert.\n   * @param obj_size The size of the object (required for GDSF).\n   */\n  void insert(obj_id_t obj_id, uint64_t obj_size) {\n    if (cache_objects.count(obj_id)) {\n      find(obj_id);\n      return;\n    }\n\n    CacheObject new_obj;\n    new_obj.size = obj_size;\n    // Give tiny objects a frequency boost to help small hot objects survive,\n    // and large objects a slight initial penalty.\n    if (obj_size < 4096) {\n      new_obj.frequency = 3;\n    } else if (obj_size > 4 * 1024 * 1024) { // >=4MB gets a penalty, harder to keep huge objects\n      new_obj.frequency = 1;\n    } else if (obj_size > 256 * 1024) {      // 256KB-4MB get moderate frequency\n      new_obj.frequency = 2;\n    } else {\n      new_obj.frequency = 2;\n    }\n\n    // Add a recency/random jitter that is a bit more diverse for improved tie-breaking\n    double pri = calculate_priority(new_obj.frequency, new_obj.size) + 0.06 * (request_counter % 9);\n\n    PQNode new_node(pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    new_obj.pq_iterator = set_iter;\n    cache_objects[obj_id] = new_obj;\n  }\n\n  /**\n   * Selects, removes, and returns the victim object to evict.\n   *\n   * The victim is the object with the *lowest* priority, which\n   * will be at the beginning of the `std::set`.\n   *\n   * @return The obj_id_t of the evicted object. Returns 0 if\n   * the cache is empty.\n   */\n  obj_id_t evict() {\n    if (priority_queue.empty()) {\n      return 0;\n    }\n\n    auto victim_node_it = priority_queue.begin();\n    obj_id_t victim_id = victim_node_it->id;\n    double victim_priority = victim_node_it->priority;\n\n    cache_objects.erase(victim_id);\n    priority_queue.erase(victim_node_it);\n    pri_last_evict = victim_priority;\n\n    return victim_id;\n  }\n};", "language": "python", "parent_id": "346f9906-e576-4271-b491-4d0adff826bb", "generation": 3, "timestamp": 1763086909.5826368, "iteration_found": 68, "metrics": {"combined_score": 0.8561, "miss_ratio_4": 0.3613, "miss_ratio_45": 0.249, "miss_ratio_450": 0.1439}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 35 lines with 39 lines", "parent_metrics": {"combined_score": 0.8561, "miss_ratio_4": 0.3612, "miss_ratio_45": 0.2482, "miss_ratio_450": 0.1439}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert C++ programmer specializing in high-performance cache eviction algorithms.\nYour task is to implement a C++ class named `CacheManager`.\n\nYou MUST provide the complete, raw C++ code, starting with #include.\n\nCRITICAL: The generated code MUST end with the final '};' that closes the class.\n\nCRITICAL: The class MUST have three public methods with these EXACT signatures. DO NOT change them:\n- `bool find(obj_id_t obj_id)`\n- `void insert(obj_id_t obj_id, uint64_t obj_size)`\n- `obj_id_t evict()`\n\nThe class MUST NOT have a custom constructor. It must use the default constructor.\n\nHere is an example of the required structure. You can change the private members and the logic inside the functions, but NOT the public class name or method signatures.\n\n```cpp\n#include <cstdint>\n#include <iomanip>\n#include <iostream>\n#include <set>\n#include <string>\n#include <unordered_map>\n\ntypedef uint64_t obj_id_t;\n\n/**\n* Implements the Greedy-Dual-Size-Frequency (GDSF) eviction policy.\n*\n* This class manages the cache eviction state. It tracks objects,\n* their sizes, and their frequencies to calculate a priority for\n* eviction. It evicts the object with the *lowest* priority.\n*\n* Priority (H-value) is calculated as: L + (Frequency / Size)\n* where 'L' is the priority of the last evicted item.\n*/\nclass CacheManager {\nprivate:\n  /**\n  * Node stored in the priority queue (std::set).\n  *\n  * We use std::set as a min-priority queue. It stores nodes\n  * ordered by priority, then by a timestamp as a tie-breaker.\n  */\n  struct PQNode {\n    double priority;\n    uint64_t timestamp; // Tie-breaker, incremented on each access\n    obj_id_t id;\n\n    // Constructor\n    PQNode(double p, uint64_t ts, obj_id_t i)\n        : priority(p), timestamp(ts), id(i) {}\n\n    // Comparison operator for std::set\n    // Orders by priority (lowest first), then timestamp\n    bool operator<(const PQNode &other) const {\n      if (priority != other.priority) {\n        return priority < other.priority;\n      }\n      return timestamp < other.timestamp;\n    }\n  };\n\n  /**\n  * Metadata for each object stored in the cache.\n  *\n  * Stored as the value in the main `cache_objects` map.\n  */\n  struct CacheObject {\n    uint64_t size;\n    uint64_t frequency;\n    // An iterator pointing to this object's entry in the\n    // priority_queue set. This allows for O(log N) removal\n    // during a `find` operation.\n    std::set<PQNode>::iterator pq_iterator;\n  };\n\n  /**\n  * Main lookup map.\n  *\n  * Maps an object's ID to its metadata (size, freq, and\n  * iterator into the priority queue).\n  */\n  std::unordered_map<obj_id_t, CacheObject> cache_objects;\n\n  /**\n  * The priority queue.\n  *\n  * Implemented as an std::set to keep items sorted by priority\n  * and allow for efficient removal from anywhere in the queue.\n  * The item at `priority_queue.begin()` is the eviction victim.\n  */\n  std::set<PQNode> priority_queue;\n\n  /**\n  *  The 'L' value in GDSF.\n  *\n  * This is the priority of the last item that was evicted.\n  * It's used as the base priority for all new and re-prioritized items.\n  */\n  double pri_last_evict = 0.0;\n\n  /**\n  * A simple counter to use as a timestamp for tie-breaking.\n  *\n  * This ensures FIFO-like behavior for items with the same priority.\n  */\n  uint64_t request_counter = 0;\n\n  /**\n  * Helper function to calculate an object's priority (H-value).\n  *\n  * From the original code: pri = L + (freq * 1.0e6 / size)\n  * The 1.0e6 is a scaling factor to keep the (freq/size)\n  * component significant.\n  */\n  double calculate_priority(uint64_t freq, uint64_t size) {\n    if (size == 0) {\n      return pri_last_evict + (double)(freq) * 1.0e6;\n    }\n    return pri_last_evict + (double)(freq) * 1.0e6 / size;\n  }\n\npublic:\n  /**\n  * Default constructor.\n  */\n  CacheManager() = default;\n\n  /**\n  * Finds an object in the cache.\n  *\n  * If the object is found, its frequency is incremented, its\n  * priority is recalculated, and its position in the\n  * priority queue is updated.\n  *\n  * @param obj_id The ID of the object to find.\n  * @return true if the object was found (a hit), false otherwise (a miss).\n  */\n  bool find(obj_id_t obj_id) {\n    auto map_iter = cache_objects.find(obj_id);\n\n    if (map_iter == cache_objects.end()) {\n      return false;\n    }\n\n    CacheObject &obj = map_iter->second;\n    priority_queue.erase(obj.pq_iterator);\n    obj.frequency += 1;\n    double new_pri = calculate_priority(obj.frequency, obj.size);\n\n    PQNode new_node(new_pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    obj.pq_iterator = set_iter;\n\n    return true;\n  }\n\n  /**\n  * Inserts a new object into the cache.\n  *\n  * Assumes this is called after a `find` reported a miss.\n  * If the object already exists, this function will behave\n  * like `find()` and update its priority.\n  *\n  * @param obj_id The ID of the object to insert.\n  * @param obj_size The size of the object (required for GDSF).\n  */\n  void insert(obj_id_t obj_id, uint64_t obj_size) {\n    if (cache_objects.count(obj_id)) {\n      find(obj_id);\n      return;\n    }\n\n    CacheObject new_obj;\n    new_obj.size = obj_size;\n    new_obj.frequency = 1;\n\n    double pri = calculate_priority(new_obj.frequency, new_obj.size);\n    PQNode new_node(pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    new_obj.pq_iterator = set_iter;\n    cache_objects[obj_id] = new_obj;\n  }\n\n  /**\n  * Selects, removes, and returns the victim object to evict.\n  *\n  * The victim is the object with the *lowest* priority, which\n  * will be at the beginning of the `std::set`.\n  *\n  * @return The obj_id_t of the evicted object. Returns 0 if\n  * the cache is empty.\n  */\n  obj_id_t evict() {\n    if (priority_queue.empty()) {\n      return 0;\n    }\n\n    auto victim_node_it = priority_queue.begin();\n    obj_id_t victim_id = victim_node_it->id;\n    double victim_priority = victim_node_it->priority;\n\n    cache_objects.erase(victim_id);\n    priority_queue.erase(victim_node_it);\n    pri_last_evict = victim_priority;\n\n    return victim_id;\n  }\n};\n```\n", "user": "# Current Program Information\n- Fitness: 0.8561\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness declined: 0.8574 \u2192 0.8561. Consider revising recent changes.\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### full_results_json\n```\n{\"score\": 0.8561, \"results\": [{\"cache_name\": \"FullCodeEvolve\", \"cache_size_mb\": 4, \"n_miss\": 1183287, \"n_req\": 3275919, \"miss_ratio\": 0.3612, \"byte_miss_ratio\": 0.6319, \"runtime_seconds\": 10.4441}, {\"cache_name\": \"FullCodeEvolve\", \"cache_size_mb\": 45, \"n_miss\": 813006, \"n_req\": 3275919, \"miss_ratio\": 0.2482, \"byte_miss_ratio\": 0.4889, \"runtime_seconds\": 10.4441}, {\"cache_name\": \"FullCodeEvolve\", \"cache_size_mb\": 450, \"n_miss\": 471303, \"n_req\": 3275919, \"miss_ratio\": 0.1439, \"byte_miss_ratio\": 0.2481, \"runtime_seconds\": 10.4441}]}\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 14 lines with 15 lines\nChange 2: Replace 10 lines with 8 lines\n- Metrics: combined_score: 0.8574, miss_ratio_4: 0.3591, miss_ratio_45: 0.2416, miss_ratio_450: 0.1426\n- Outcome: Improvement in all metrics\n\n### Attempt 2\n- Changes: Change 1: Replace 17 lines with 18 lines\nChange 2: Replace 16 lines with 20 lines\n- Metrics: combined_score: 0.8574, miss_ratio_4: 0.3605, miss_ratio_45: 0.2398, miss_ratio_450: 0.1426\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Change 1: Replace 27 lines with 28 lines\n- Metrics: combined_score: 0.8574, miss_ratio_4: 0.3605, miss_ratio_45: 0.2399, miss_ratio_450: 0.1426\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.8574)\n```python\n#include <cstdint>\n#include <iomanip>\n#include <iostream>\n#include <set>\n#include <string>\n#include <unordered_map>\n\ntypedef uint64_t obj_id_t;\n\n/**\n * Implements the Greedy-Dual-Size-Frequency (GDSF) eviction policy.\n *\n * This class manages the cache eviction state. It tracks objects,\n * their sizes, and their frequencies to calculate a priority for\n * eviction. It evicts the object with the *lowest* priority.\n *\n * Priority (H-value) is calculated as: L + (Frequency / Size)\n * where 'L' is the priority of the last evicted item.\n */\nclass CacheManager {\nprivate:\n  /**\n   * Node stored in the priority queue (std::set).\n   *\n   * We use std::set as a min-priority queue. It stores nodes\n   * ordered by priority, then by a timestamp as a tie-breaker.\n   */\n  struct PQNode {\n    double priority;\n    uint64_t timestamp; // Tie-breaker, incremented on each access\n    obj_id_t id;\n\n    // Constructor\n    PQNode(double p, uint64_t ts, obj_id_t i)\n        : priority(p), timestamp(ts), id(i) {}\n\n    // Comparison operator for std::set\n    // Orders by priority (lowest first), then timestamp\n    bool operator<(const PQNode &other) const {\n      if (priority != other.priority) {\n        return priority < other.priority;\n      }\n      return timestamp < other.timestamp;\n    }\n  };\n\n  /**\n   * Metadata for each object stored in the cache.\n   *\n   * Stored as the value in the main `cache_objects` map.\n   */\n  struct CacheObject {\n    uint64_t size;\n    uint64_t frequency;\n    // An iterator pointing to this object's entry in the\n    // priority_queue set. This allows for O(log N) removal\n    // during a `find` operation.\n    std::set<PQNode>::iterator pq_iterator;\n  };\n\n  /**\n   * Main lookup map.\n   *\n   * Maps an object's ID to its metadata (size, freq, and\n   * iterator into the priority queue).\n   */\n  std::unordered_map<obj_id_t, CacheObject> cache_objects;\n\n  /**\n   * The priority queue.\n   *\n   * Implemented as an std::set to keep items sorted by priority\n   * and allow for efficient removal from anywhere in the queue.\n   * The item at `priority_queue.begin()` is the eviction victim.\n   */\n  std::set<PQNode> priority_queue;\n\n  /**\n   *  The 'L' value in GDSF.\n   *\n   * This is the priority of the last item that was evicted.\n   * It's used as the base priority for all new and re-prioritized items.\n   */\n  double pri_last_evict = 0.0;\n\n  /**\n   * A simple counter to use as a timestamp for tie-breaking.\n   *\n   * This ensures FIFO-like behavior for items with the same priority.\n   */\n  uint64_t request_counter = 0;\n\n  /**\n   * Helper function to calculate an object's priority (H-value).\n   *\n   * The priority is computed as:\n   *   pri = L + (freq * 2.0e5 / size) + recency_boost\n   * where L is the last evicted priority, freq is usage count,\n   * and recency_boost makes very recent objects slightly less likely to be evicted.\n   * \n   * This rewards recency more directly, aiding hot set adaptation.\n   * Increase freq/size scaling to protect both frequently accessed and small objects.\n   */\n  double calculate_priority(uint64_t freq, uint64_t size) {\n    const double recency_boost = 0.13 * (request_counter % 6); // recency bonus in [0, 0.65]\n    if (size == 0) {\n      return pri_last_evict + (double)(freq) * 2.0e5 + recency_boost;\n    }\n    return pri_last_evict + (double)(freq) * 2.0e5 / size + recency_boost;\n  }\n\npublic:\n  /**\n   * Default constructor.\n   */\n  CacheManager() = default;\n\n  /**\n   * Finds an object in the cache.\n   *\n   * If the object is found, its frequency is incremented, its\n   * priority is recalculated, and its position in the\n   * priority queue is updated.\n   *\n   * @param obj_id The ID of the object to find.\n   * @return true if the object was found (a hit), false otherwise (a miss).\n   */\n  bool find(obj_id_t obj_id) {\n    auto map_iter = cache_objects.find(obj_id);\n\n    if (map_iter == cache_objects.end()) {\n      return false;\n    }\n\n    CacheObject &obj = map_iter->second;\n    priority_queue.erase(obj.pq_iterator);\n    obj.frequency += 1;\n    double new_pri = calculate_priority(obj.frequency, obj.size);\n\n    PQNode new_node(new_pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    obj.pq_iterator = set_iter;\n\n    return true;\n  }\n\n  /**\n   * Inserts a new object into the cache.\n   *\n   * Assumes this is called after a `find` reported a miss.\n   * If the object already exists, this function will behave\n   * like `find()` and update its priority.\n   *\n   * @param obj_id The ID of the object to insert.\n   * @param obj_size The size of the object (required for GDSF).\n   */\n  void insert(obj_id_t obj_id, uint64_t obj_size) {\n    if (cache_objects.count(obj_id)) {\n      find(obj_id);\n      return;\n    }\n\n    CacheObject new_obj;\n    new_obj.size = obj_size;\n\n    // Revised initial frequency: 2 for tiny, 3 for huge, 2 for large, 1 for other\n    if (obj_size < 4096) {\n      new_obj.frequency = 2;\n    } else if (obj_size > 2 * 1024 * 1024) { // >2MB gets biggest boost\n      new_obj.frequency = 3;\n    } else if (obj_size > 256 * 1024) { // 256KB-2MB gets moderate boost\n      new_obj.frequency = 2;\n    } else {\n      new_obj.frequency = 1;\n    }\n\n    double pri = calculate_priority(new_obj.frequency, new_obj.size) + 0.05 * (request_counter % 4);\n\n    PQNode new_node(pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    new_obj.pq_iterator = set_iter;\n    cache_objects[obj_id] = new_obj;\n  }\n\n  /**\n   * Selects, removes, and returns the victim object to evict.\n   *\n   * The victim is the object with the *lowest* priority, which\n   * will be at the beginning of the `std::set`.\n   *\n   * @return The obj_id_t of the evicted object. Returns 0 if\n   * the cache is empty.\n   */\n  obj_id_t evict() {\n    if (priority_queue.empty()) {\n      return 0;\n    }\n\n    auto victim_node_it = priority_queue.begin();\n    obj_id_t victim_id = victim_node_it->id;\n    double victim_priority = victim_node_it->priority;\n\n    cache_objects.erase(victim_id);\n    priority_queue.erase(victim_node_it);\n    pri_last_evict = victim_priority;\n\n    return victim_id;\n  }\n};\n```\nKey features: Performs well on combined_score (0.8574), Performs well on miss_ratio_4 (0.3605), Performs well on miss_ratio_45 (0.2399), Performs well on miss_ratio_450 (0.1426)\n\n### Program 2 (Score: 0.8574)\n```python\n#include <cstdint>\n#include <iomanip>\n#include <iostream>\n#include <set>\n#include <string>\n#include <unordered_map>\n\ntypedef uint64_t obj_id_t;\n\n/**\n * Implements the Greedy-Dual-Size-Frequency (GDSF) eviction policy.\n *\n * This class manages the cache eviction state. It tracks objects,\n * their sizes, and their frequencies to calculate a priority for\n * eviction. It evicts the object with the *lowest* priority.\n *\n * Priority (H-value) is calculated as: L + (Frequency / Size)\n * where 'L' is the priority of the last evicted item.\n */\nclass CacheManager {\nprivate:\n  /**\n   * Node stored in the priority queue (std::set).\n   *\n   * We use std::set as a min-priority queue. It stores nodes\n   * ordered by priority, then by a timestamp as a tie-breaker.\n   */\n  struct PQNode {\n    double priority;\n    uint64_t timestamp; // Tie-breaker, incremented on each access\n    obj_id_t id;\n\n    // Constructor\n    PQNode(double p, uint64_t ts, obj_id_t i)\n        : priority(p), timestamp(ts), id(i) {}\n\n    // Comparison operator for std::set\n    // Orders by priority (lowest first), then timestamp\n    bool operator<(const PQNode &other) const {\n      if (priority != other.priority) {\n        return priority < other.priority;\n      }\n      return timestamp < other.timestamp;\n    }\n  };\n\n  /**\n   * Metadata for each object stored in the cache.\n   *\n   * Stored as the value in the main `cache_objects` map.\n   */\n  struct CacheObject {\n    uint64_t size;\n    uint64_t frequency;\n    // An iterator pointing to this object's entry in the\n    // priority_queue set. This allows for O(log N) removal\n    // during a `find` operation.\n    std::set<PQNode>::iterator pq_iterator;\n  };\n\n  /**\n   * Main lookup map.\n   *\n   * Maps an object's ID to its metadata (size, freq, and\n   * iterator into the priority queue).\n   */\n  std::unordered_map<obj_id_t, CacheObject> cache_objects;\n\n  /**\n   * The priority queue.\n   *\n   * Implemented as an std::set to keep items sorted by priority\n   * and allow for efficient removal from anywhere in the queue.\n   * The item at `priority_queue.begin()` is the eviction victim.\n   */\n  std::set<PQNode> priority_queue;\n\n  /**\n   *  The 'L' value in GDSF.\n   *\n   * This is the priority of the last item that was evicted.\n   * It's used as the base priority for all new and re-prioritized items.\n   */\n  double pri_last_evict = 0.0;\n\n  /**\n   * A simple counter to use as a timestamp for tie-breaking.\n   *\n   * This ensures FIFO-like behavior for items with the same priority.\n   */\n  uint64_t request_counter = 0;\n\n  /**\n   * Helper function to calculate an object's priority (H-value).\n   *\n   * The priority is computed as:\n   *   pri = L + (freq * 2.0e5 / size) + recency_boost\n   * where L is the last evicted priority, freq is usage count,\n   * and recency_boost makes very recent objects slightly less likely to be evicted.\n   * \n   * This rewards recency more directly, aiding hot set adaptation.\n   * Increase freq/size scaling to protect both frequently accessed and small objects.\n   */\n  double calculate_priority(uint64_t freq, uint64_t size) {\n    const double recency_boost = 0.13 * (request_counter % 6); // recency bonus in [0, 0.65]\n    if (size == 0) {\n      return pri_last_evict + (double)(freq) * 2.0e5 + recency_boost;\n    }\n    return pri_last_evict + (double)(freq) * 2.0e5 / size + recency_boost;\n  }\n\npublic:\n  /**\n   * Default constructor.\n   */\n  CacheManager() = default;\n\n  /**\n   * Finds an object in the cache.\n   *\n   * If the object is found, its frequency is incremented, its\n   * priority is recalculated, and its position in the\n   * priority queue is updated.\n   *\n   * @param obj_id The ID of the object to find.\n   * @return true if the object was found (a hit), false otherwise (a miss).\n   */\n  bool find(obj_id_t obj_id) {\n    auto map_iter = cache_objects.find(obj_id);\n\n    if (map_iter == cache_objects.end()) {\n      return false;\n    }\n\n    CacheObject &obj = map_iter->second;\n    priority_queue.erase(obj.pq_iterator);\n    obj.frequency += 1;\n    double new_pri = calculate_priority(obj.frequency, obj.size);\n\n    PQNode new_node(new_pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    obj.pq_iterator = set_iter;\n\n    return true;\n  }\n\n  /**\n   * Inserts a new object into the cache.\n   *\n   * Assumes this is called after a `find` reported a miss.\n   * If the object already exists, this function will behave\n   * like `find()` and update its priority.\n   *\n   * @param obj_id The ID of the object to insert.\n   * @param obj_size The size of the object (required for GDSF).\n   */\n  void insert(obj_id_t obj_id, uint64_t obj_size) {\n    if (cache_objects.count(obj_id)) {\n      find(obj_id);\n      return;\n    }\n\n    CacheObject new_obj;\n    new_obj.size = obj_size;\n\n    // Adjust initial frequency:\n    // Give frequency 2 to tiny objects, frequency 1 to normal/large, but 3 to very large objects.\n    if (obj_size < 4096) {\n      new_obj.frequency = 2;\n    } else if (obj_size > 1024 * 1024) {\n      new_obj.frequency = 3;\n    } else {\n      new_obj.frequency = 1;\n    }\n\n    double pri = calculate_priority(new_obj.frequency, new_obj.size);\n\n    PQNode new_node(pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    new_obj.pq_iterator = set_iter;\n    cache_objects[obj_id] = new_obj;\n  }\n\n  /**\n   * Selects, removes, and returns the victim object to evict.\n   *\n   * The victim is the object with the *lowest* priority, which\n   * will be at the beginning of the `std::set`.\n   *\n   * @return The obj_id_t of the evicted object. Returns 0 if\n   * the cache is empty.\n   */\n  obj_id_t evict() {\n    if (priority_queue.empty()) {\n      return 0;\n    }\n\n    auto victim_node_it = priority_queue.begin();\n    obj_id_t victim_id = victim_node_it->id;\n    double victim_priority = victim_node_it->priority;\n\n    cache_objects.erase(victim_id);\n    priority_queue.erase(victim_node_it);\n    pri_last_evict = victim_priority;\n\n    return victim_id;\n  }\n};\n```\nKey features: Performs well on combined_score (0.8574), Performs well on miss_ratio_4 (0.3605), Performs well on miss_ratio_45 (0.2398), Performs well on miss_ratio_450 (0.1426)\n\n### Program 3 (Score: 0.8574)\n```python\n#include <cstdint>\n#include <iomanip>\n#include <iostream>\n#include <set>\n#include <string>\n#include <unordered_map>\n\ntypedef uint64_t obj_id_t;\n\n/**\n * Implements the Greedy-Dual-Size-Frequency (GDSF) eviction policy.\n *\n * This class manages the cache eviction state. It tracks objects,\n * their sizes, and their frequencies to calculate a priority for\n * eviction. It evicts the object with the *lowest* priority.\n *\n * Priority (H-value) is calculated as: L + (Frequency / Size)\n * where 'L' is the priority of the last evicted item.\n */\nclass CacheManager {\nprivate:\n  /**\n   * Node stored in the priority queue (std::set).\n   *\n   * We use std::set as a min-priority queue. It stores nodes\n   * ordered by priority, then by a timestamp as a tie-breaker.\n   */\n  struct PQNode {\n    double priority;\n    uint64_t timestamp; // Tie-breaker, incremented on each access\n    obj_id_t id;\n\n    // Constructor\n    PQNode(double p, uint64_t ts, obj_id_t i)\n        : priority(p), timestamp(ts), id(i) {}\n\n    // Comparison operator for std::set\n    // Orders by priority (lowest first), then timestamp\n    bool operator<(const PQNode &other) const {\n      if (priority != other.priority) {\n        return priority < other.priority;\n      }\n      return timestamp < other.timestamp;\n    }\n  };\n\n  /**\n   * Metadata for each object stored in the cache.\n   *\n   * Stored as the value in the main `cache_objects` map.\n   */\n  struct CacheObject {\n    uint64_t size;\n    uint64_t frequency;\n    // An iterator pointing to this object's entry in the\n    // priority_queue set. This allows for O(log N) removal\n    // during a `find` operation.\n    std::set<PQNode>::iterator pq_iterator;\n  };\n\n  /**\n   * Main lookup map.\n   *\n   * Maps an object's ID to its metadata (size, freq, and\n   * iterator into the priority queue).\n   */\n  std::unordered_map<obj_id_t, CacheObject> cache_objects;\n\n  /**\n   * The priority queue.\n   *\n   * Implemented as an std::set to keep items sorted by priority\n   * and allow for efficient removal from anywhere in the queue.\n   * The item at `priority_queue.begin()` is the eviction victim.\n   */\n  std::set<PQNode> priority_queue;\n\n  /**\n   *  The 'L' value in GDSF.\n   *\n   * This is the priority of the last item that was evicted.\n   * It's used as the base priority for all new and re-prioritized items.\n   */\n  double pri_last_evict = 0.0;\n\n  /**\n   * A simple counter to use as a timestamp for tie-breaking.\n   *\n   * This ensures FIFO-like behavior for items with the same priority.\n   */\n  uint64_t request_counter = 0;\n\n  /**\n   * Helper function to calculate an object's priority (H-value).\n   *\n   * From the original code: pri = L + (freq * 1.0e6 / size)\n   * The 1.0e6 is a scaling factor to keep the (freq/size)\n   * component significant.\n   * Increase the scaling factor slightly to re-emphasize frequency/size\n   * and to further distinguish items, but use 2.0e5 for diversity.\n   */\n  double calculate_priority(uint64_t freq, uint64_t size) {\n    if (size == 0) {\n      return pri_last_evict + (double)(freq) * 2.0e5;\n    }\n    return pri_last_evict + (double)(freq) * 2.0e5 / size;\n  }\n\npublic:\n  /**\n   * Default constructor.\n   */\n  CacheManager() = default;\n\n  /**\n   * Finds an object in the cache.\n   *\n   * If the object is found, its frequency is incremented, its\n   * priority is recalculated, and its position in the\n   * priority queue is updated.\n   *\n   * @param obj_id The ID of the object to find.\n   * @return true if the object was found (a hit), false otherwise (a miss).\n   */\n  bool find(obj_id_t obj_id) {\n    auto map_iter = cache_objects.find(obj_id);\n\n    if (map_iter == cache_objects.end()) {\n      return false;\n    }\n\n    CacheObject &obj = map_iter->second;\n    priority_queue.erase(obj.pq_iterator);\n    obj.frequency += 1;\n    double new_pri = calculate_priority(obj.frequency, obj.size);\n\n    PQNode new_node(new_pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    obj.pq_iterator = set_iter;\n\n    return true;\n  }\n\n  /**\n   * Inserts a new object into the cache.\n   *\n   * Assumes this is called after a `find` reported a miss.\n   * If the object already exists, this function will behave\n   * like `find()` and update its priority.\n   *\n   * @param obj_id The ID of the object to insert.\n   * @param obj_size The size of the object (required for GDSF).\n   */\n  void insert(obj_id_t obj_id, uint64_t obj_size) {\n    if (cache_objects.count(obj_id)) {\n      find(obj_id);\n      return;\n    }\n\n    CacheObject new_obj;\n    new_obj.size = obj_size;\n    new_obj.frequency = 1;\n\n    // Give newly inserted objects a slight recency bonus for diversity in entry selection\n    double pri = calculate_priority(new_obj.frequency, new_obj.size) + 0.1;\n\n    PQNode new_node(pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    new_obj.pq_iterator = set_iter;\n    cache_objects[obj_id] = new_obj;\n  }\n\n  /**\n   * Selects, removes, and returns the victim object to evict.\n   *\n   * The victim is the object with the *lowest* priority, which\n   * will be at the beginning of the `std::set`.\n   *\n   * @return The obj_id_t of the evicted object. Returns 0 if\n   * the cache is empty.\n   */\n  obj_id_t evict() {\n    if (priority_queue.empty()) {\n      return 0;\n    }\n\n    auto victim_node_it = priority_queue.begin();\n    obj_id_t victim_id = victim_node_it->id;\n    double victim_priority = victim_node_it->priority;\n\n    cache_objects.erase(victim_id);\n    priority_queue.erase(victim_node_it);\n    pri_last_evict = victim_priority;\n\n    return victim_id;\n  }\n};\n```\nKey features: Performs well on combined_score (0.8574), Performs well on miss_ratio_4 (0.3591), Performs well on miss_ratio_45 (0.2416), Performs well on miss_ratio_450 (0.1426)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.8573)\n```python\n#include <cstdint>\n#include <iomanip>\n#include <iostream>\n#include <set>\n#include <string>\n#include <unordered_map>\n\ntypedef uint64_t obj_id_t;\n\n/**\n * Implements the Greedy-Dual-Size-Frequency (GDSF) eviction policy.\n *\n * This class manages the cache eviction state. It tracks objects,\n * their sizes, and their frequencies to calculate a priority for\n * eviction. It evicts the object with the *lowest* priority.\n *\n * Priority (H-value) is calculated as: L + (Frequency / Size)\n * where 'L' is the priority of the last evicted item.\n */\nclass CacheManager {\nprivate:\n  /**\n   * Node stored in the priority queue (std::set).\n   *\n   * We use std::set as a min-priority queue. It stores nodes\n   * ordered by priority, then by a timestamp as a tie-breaker.\n   */\n  struct PQNode {\n    double priority;\n    uint64_t timestamp; // Tie-breaker, incremented on each access\n    obj_id_t id;\n\n    // Constructor\n    PQNode(double p, uint64_t ts, obj_id_t i)\n        : priority(p), timestamp(ts), id(i) {}\n\n    // Comparison operator for std::set\n    // Orders by priority (lowest first), then timestamp\n    bool operator<(const PQNode &other) const {\n      if (priority != other.priority) {\n        return priority < other.priority;\n      }\n      return timestamp < other.timestamp;\n    }\n  };\n\n  /**\n   * Metadata for each object stored in the cache.\n   *\n   * Stored as the value in the main `cache_objects` map.\n   */\n  struct CacheObject {\n    uint64_t size;\n    uint64_t frequency;\n    // An iterator pointing to this object's entry in the\n    // priority_queue set. This allows for O(log N) removal\n    // during a `find` operation.\n    std::set<PQNode>::iterator pq_iterator;\n  };\n\n  /**\n   * Main lookup map.\n   *\n   * Maps an object's ID to its metadata (size, freq, and\n   * iterator into the priority queue).\n   */\n  std::unordered_map<obj_id_t, CacheObject> cache_objects;\n\n  /**\n   * The priority queue.\n   *\n   * Implemented as an std::set to keep items sorted by priority\n   * and allow for efficient removal from anywhere in the queue.\n   * The item at `priority_queue.begin()` is the eviction victim.\n   */\n  std::set<PQNode> priority_queue;\n\n  /**\n   *  The 'L' value in GDSF.\n   *\n   * This is the priority of the last item that was evicted.\n   * It's used as the base priority for all new and re-prioritized items.\n   */\n  double pri_last_evict = 0.0;\n\n  /**\n   * A simple counter to use as a timestamp for tie-breaking.\n   *\n   * This ensures FIFO-like behavior for items with the same priority.\n   */\n  uint64_t request_counter = 0;\n\n  /**\n   * Helper function to calculate an object's priority (H-value).\n   *\n   * From the original code: pri = L + (freq * 1.0e6 / size)\n   * The 1.0e6 is a scaling factor to keep the (freq/size)\n   * component significant.\n   */\n  // Reduce scaling factor from 1.0e6 to 1.0e5 to minimize domination of freq/size over recency\n  double calculate_priority(uint64_t freq, uint64_t size) {\n    if (size == 0) {\n      return pri_last_evict + (double)(freq) * 1.0e5;\n    }\n    return pri_last_evict + (double)(freq) * 1.0e5 / size;\n  }\n\npublic:\n  /**\n   * Default constructor.\n   */\n  CacheManager() = default;\n\n  /**\n   * Finds an object in the cache.\n   *\n   * If the object is found, its frequency is incremented, its\n   * priority is recalculated, and its position in the\n   * priority queue is updated.\n   *\n   * @param obj_id The ID of the object to find.\n   * @return true if the object was found (a hit), false otherwise (a miss).\n   */\n  bool find(obj_id_t obj_id) {\n    auto map_iter = cache_objects.find(obj_id);\n\n    if (map_iter == cache_objects.end()) {\n      return false;\n    }\n\n    CacheObject &obj = map_iter->second;\n    priority_queue.erase(obj.pq_iterator);\n    obj.frequency += 1;\n    double new_pri = calculate_priority(obj.frequency, obj.size);\n\n    PQNode new_node(new_pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    obj.pq_iterator = set_iter;\n\n    return true;\n  }\n\n  /**\n   * Inserts a new object into the cache.\n   *\n   * Assumes this is called after a `find` reported a miss.\n   * If the object already exists, this function will behave\n   * like `find()` and update its priority.\n   *\n   * @param obj_id The ID of the object to insert.\n   * @param obj_size The size of the object (required for GDSF).\n   */\n  void insert(obj_id_t obj_id, uint64_t obj_size) {\n    if (cache_objects.count(obj_id)) {\n      find(obj_id);\n      return;\n    }\n\n    CacheObject new_obj;\n    new_obj.size = obj_size;\n    // Start frequency higher for tiny objects to better protect small but reusable entries\n    if (obj_size < 4096) {\n      new_obj.frequency = 2;\n    } else {\n      new_obj.frequency = 1;\n    }\n\n    double pri = calculate_priority(new_obj.frequency, new_obj.size);\n    // No randomization needed; timestamp tie-breaker already present\n\n    PQNode new_node(pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    new_obj.pq_iterator = set_iter;\n    cache_objects[obj_id] = new_obj;\n  }\n\n  /**\n   * Selects, removes, and returns the victim object to evict.\n   *\n   * The victim is the object with the *lowest* priority, which\n   * will be at the beginning of the `std::set`.\n   *\n   * @return The obj_id_t of the evicted object. Returns 0 if\n   * the cache is empty.\n   */\n  obj_id_t evict() {\n    if (priority_queue.empty()) {\n      return 0;\n    }\n\n    auto victim_node_it = priority_queue.begin();\n    obj_id_t victim_id = victim_node_it->id;\n    double victim_priority = victim_node_it->priority;\n\n    cache_objects.erase(victim_id);\n    priority_queue.erase(victim_node_it);\n    pri_last_evict = victim_priority;\n\n    return victim_id;\n  }\n};\n```\nKey features: Alternative approach to combined_score, Alternative approach to miss_ratio_4\n\n### Program D2 (Score: 0.8572)\n```python\n#include <cstdint>\n#include <iomanip>\n#include <iostream>\n#include <set>\n#include <string>\n#include <unordered_map>\n\ntypedef uint64_t obj_id_t;\n\n/**\n * Implements the Greedy-Dual-Size-Frequency (GDSF) eviction policy.\n *\n * This class manages the cache eviction state. It tracks objects,\n * their sizes, and their frequencies to calculate a priority for\n * eviction. It evicts the object with the *lowest* priority.\n *\n * Priority (H-value) is calculated as: L + (Frequency / Size)\n * where 'L' is the priority of the last evicted item.\n */\nclass CacheManager {\nprivate:\n  /**\n   * Node stored in the priority queue (std::set).\n   *\n   * We use std::set as a min-priority queue. It stores nodes\n   * ordered by priority, then by a timestamp as a tie-breaker.\n   */\n  struct PQNode {\n    double priority;\n    uint64_t timestamp; // Tie-breaker, incremented on each access\n    obj_id_t id;\n\n    // Constructor\n    PQNode(double p, uint64_t ts, obj_id_t i)\n        : priority(p), timestamp(ts), id(i) {}\n\n    // Comparison operator for std::set\n    // Orders by priority (lowest first), then timestamp\n    bool operator<(const PQNode &other) const {\n      if (priority != other.priority) {\n        return priority < other.priority;\n      }\n      return timestamp < other.timestamp;\n    }\n  };\n\n  /**\n   * Metadata for each object stored in the cache.\n   *\n   * Stored as the value in the main `cache_objects` map.\n   */\n  struct CacheObject {\n    uint64_t size;\n    uint64_t frequency;\n    // An iterator pointing to this object's entry in the\n    // priority_queue set. This allows for O(log N) removal\n    // during a `find` operation.\n    std::set<PQNode>::iterator pq_iterator;\n  };\n\n  /**\n   * Main lookup map.\n   *\n   * Maps an object's ID to its metadata (size, freq, and\n   * iterator into the priority queue).\n   */\n  std::unordered_map<obj_id_t, CacheObject> cache_objects;\n\n  /**\n   * The priority queue.\n   *\n   * Implemented as an std::set to keep items sorted by priority\n   * and allow for efficient removal from anywhere in the queue.\n   * The item at `priority_queue.begin()` is the eviction victim.\n   */\n  std::set<PQNode> priority_queue;\n\n  /**\n   *  The 'L' value in GDSF.\n   *\n   * This is the priority of the last item that was evicted.\n   * It's used as the base priority for all new and re-prioritized items.\n   */\n  double pri_last_evict = 0.0;\n\n  /**\n   * A simple counter to use as a timestamp for tie-breaking.\n   *\n   * This ensures FIFO-like behavior for items with the same priority.\n   */\n  uint64_t request_counter = 0;\n\n  /**\n   * Helper function to calculate an object's priority (H-value).\n   *\n   * Boosts recency slightly, but relies mostly on freq/size.\n   * Uses a lower scaling for freq/size for more balance, and\n   * adds a small recency jitter to increase priority diversity.\n   */\n  double calculate_priority(uint64_t freq, uint64_t size) {\n    constexpr double scaling = 1.2e5; // softer scaling, more recency responsive\n    double recency_jitter = 0.08 * (request_counter % 10); // [0,0.72]\n    if (size == 0) {\n      return pri_last_evict + (double)(freq) * scaling + recency_jitter;\n    }\n    return pri_last_evict + (double)(freq) * scaling / size + recency_jitter;\n  }\n\npublic:\n  /**\n   * Default constructor.\n   */\n  CacheManager() = default;\n\n  /**\n   * Finds an object in the cache.\n   *\n   * If the object is found, its frequency is incremented, its\n   * priority is recalculated, and its position in the\n   * priority queue is updated.\n   *\n   * @param obj_id The ID of the object to find.\n   * @return true if the object was found (a hit), false otherwise (a miss).\n   */\n  bool find(obj_id_t obj_id) {\n    auto map_iter = cache_objects.find(obj_id);\n\n    if (map_iter == cache_objects.end()) {\n      return false;\n    }\n\n    CacheObject &obj = map_iter->second;\n    priority_queue.erase(obj.pq_iterator);\n    obj.frequency += 1;\n    double new_pri = calculate_priority(obj.frequency, obj.size);\n\n    PQNode new_node(new_pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    obj.pq_iterator = set_iter;\n\n    return true;\n  }\n\n  /**\n   * Inserts a new object into the cache.\n   *\n   * Assumes this is called after a `find` reported a miss.\n   * If the object already exists, this function will behave\n   * like `find()` and update its priority.\n   *\n   * @param obj_id The ID of the object to insert.\n   * @param obj_size The size of the object (required for GDSF).\n   */\n  void insert(obj_id_t obj_id, uint64_t obj_size) {\n    if (cache_objects.count(obj_id)) {\n      find(obj_id);\n      return;\n    }\n\n    CacheObject new_obj;\n    new_obj.size = obj_size;\n\n    // Size-based initial frequency: tiny & huge objects get a bigger boost.\n    if (obj_size < 4096) {\n      new_obj.frequency = 2;\n    } else if (obj_size > 2 * 1024 * 1024) {\n      new_obj.frequency = 3;\n    } else if (obj_size > 256 * 1024) {\n      new_obj.frequency = 2;\n    } else {\n      new_obj.frequency = 1;\n    }\n\n    double pri = calculate_priority(new_obj.frequency, new_obj.size) + 0.03 * (request_counter % 4);\n\n    PQNode new_node(pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    new_obj.pq_iterator = set_iter;\n    cache_objects[obj_id] = new_obj;\n  }\n\n  /**\n   * Selects, removes, and returns the victim object to evict.\n   *\n   * The victim is the object with the *lowest* priority, which\n   * will be at the beginning of the `std::set`.\n   *\n   * @return The obj_id_t of the evicted object. Returns 0 if\n   * the cache is empty.\n   */\n  obj_id_t evict() {\n    if (priority_queue.empty()) {\n      return 0;\n    }\n\n    auto victim_node_it = priority_queue.begin();\n    obj_id_t victim_id = victim_node_it->id;\n    double victim_priority = victim_node_it->priority;\n\n    cache_objects.erase(victim_id);\n    priority_queue.erase(victim_node_it);\n    pri_last_evict = victim_priority;\n\n    return victim_id;\n  }\n};\n```\nKey features: Alternative approach to combined_score, Alternative approach to miss_ratio_4\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: -inf, Type: Exploratory)\n```python\n#include <cstdint>\n#include <iomanip>\n#include <iostream>\n#include <set>\n#include <string>\n#include <unordered_map>\n\ntypedef uint64_t obj_id_t;\n\n/**\n * Implements the Greedy-Dual-Size-Frequency (GDSF) eviction policy.\n *\n * This class manages the cache eviction state. It tracks objects,\n * their sizes, and their frequencies to calculate a priority for\n * eviction. It evicts the object with the *lowest* priority.\n *\n * Priority (H-value) is calculated as: L + (Frequency / Size)\n * where 'L' is the priority of the last evicted item.\n */\nclass CacheManager {\nprivate:\n  /**\n   * Node stored in the priority queue (std::set).\n   *\n   * We use std::set as a min-priority queue. It stores nodes\n   * ordered by priority, then by a timestamp as a tie-breaker.\n   */\n  struct PQNode {\n    double priority;\n    uint64_t timestamp; // Tie-breaker, incremented on each access\n    obj_id_t id;\n\n    // Constructor\n    PQNode(double p, uint64_t ts, obj_id_t i)\n        : priority(p), timestamp(ts), id(i) {}\n\n    // Comparison operator for std::set\n    // Orders by priority (lowest first), then timestamp\n    bool operator<(const PQNode &other) const {\n      if (priority != other.priority) {\n        return priority < other.priority;\n      }\n      return timestamp < other.timestamp;\n    }\n  };\n\n  /**\n   * Metadata for each object stored in the cache.\n   *\n   * Stored as the value in the main `cache_objects` map.\n   */\n  struct CacheObject {\n    uint64_t size;\n    uint64_t frequency;\n    // An iterator pointing to this object's entry in the\n    // priority_queue set. This allows for O(log N) removal\n    // during a `find` operation.\n    std::set<PQNode>::iterator pq_iterator;\n  };\n\n  /**\n   * Main lookup map.\n   *\n   * Maps an object's ID to its metadata (size, freq, and\n   * iterator into the priority queue).\n   */\n  std::unordered_map<obj_id_t, CacheObject> cache_objects;\n\n  /**\n   * The priority queue.\n   *\n   * Implemented as an std::set to keep items sorted by priority\n   * and allow for efficient removal from anywhere in the queue.\n   * The item at `priority_queue.begin()` is the eviction victim.\n   */\n  std::set<PQNode> priority_queue;\n\n  /**\n   *  The 'L' value in GDSF.\n   *\n   * This is the priority of the last item that was evicted.\n   * It's used as the base priority for all new and re-prioritized items.\n   */\n  double pri_last_evict = 0.0;\n\n  /**\n   * A simple counter to use as a timestamp for tie-breaking.\n   *\n   * This ensures FIFO-like behavior for items with the same priority.\n   */\n  uint64_t request_counter = 0;\n\n  /**\n   * Helper function to calculate an object's priority (H-value).\n   *\n   * Reduced the frequency/size scaling to 1.3e5 and expanded the recency_boost range\n   * for a more balanced GDSF/LRU blend. This increases hot set reactivity, especially\n   * at smaller cache sizes, while still rewarding frequency and size.\n   */\n  double calculate_priority(uint64_t freq, uint64_t size) {\n    const double recency_boost = 0.16 * (request_counter % 8); // [0,1.12]\n    if (size == 0) {\n      return pri_last_evict + (double)(freq) * 1.3e5 + recency_boost;\n    }\n    return pri_last_evict + (double)(freq) * 1.3e5 / size + recency_boost;\n  }\n\npublic:\n  /**\n   * Default constructor.\n   */\n  CacheManager() = default;\n\n  /**\n   * Finds an object in the cache.\n   *\n   * If the object is found, its frequency is incremented, its\n   * priority is recalculated, and its position in the\n   * priority queue is updated.\n   *\n   * @param obj_id The ID of the object to find.\n   * @return true if the object was found (a hit), false otherwise (a miss).\n   */\n  bool find(obj_id_t obj_id) {\n    auto map_iter = cache_objects.find(obj_id);\n\n    if (map_iter == cache_objects.end()) {\n      return false;\n    }\n\n    CacheObject &obj = map_iter->second;\n    priority_queue.erase(obj.pq_iterator);\n    obj.frequency += 1;\n    double new_pri = calculate_priority(obj.frequency, obj.size);\n\n    PQNode new_node(new_pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    obj.pq_iterator = set_iter;\n\n    return true;\n  }\n\n  /**\n   * Inserts a new object into the cache.\n   *\n   * Assumes this is called after a `find` reported a miss.\n   * If the object already exists, this function will behave\n   * like `find()` and update its priority.\n   *\n   * @param obj_id The ID of the object to insert.\n   * @param obj_size The size of the object (required for GDSF).\n   */\n  void insert(obj_id_t obj_id, uint64_t obj_size) {\n    if (cache_objects.count(obj_id)) {\n      find(obj_id);\n      return;\n    }\n\n    CacheObject new_obj;\n    new_obj.size = obj_size;\n\n    // Size-based initial frequency:\n    // freq=2 for tiny, 3 for huge, 1 for others (slightly simpler, less tuning)\n    if (obj_size < 4096) {\n      new_obj.frequency = 2;\n    } else if (obj_size > 2 * 1024 * 1024) {\n      new_obj.frequency = 3;\n    } else {\n      new_obj.frequency = 1;\n    }\n\n    // Add a small random jitter for diversity in insert priority\n    double pri = calculate_priority(new_obj.frequency, new_obj.size) + 0.07 * (request_counter % 7);\n\n    PQNode new_node(pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    new_obj.pq_iterator = set_iter;\n    cache_objects[obj_id] = new_obj;\n  }\n\n  /**\n   * Selects, removes, and returns the victim object to evict.\n   *\n   * The victim is the object with the *lowest* priority, which\n   * will be at the beginning of the `std::set`.\n   *\n   * @return The obj_id_t of the evicted object. Returns 0 if\n   * the cache is empty.\n   */\n  obj_id_t evict() {\n    if (priority_queue.empty()) {\n      return 0;\n    }\n\n    auto victim_node_it = priority_queue.begin();\n    obj_id_t victim_id = victim_node_it->id;\n    double victim_priority = victim_node_it->priority;\n\n    cache_objects.erase(victim_id);\n    priority_queue.erase(victim_node_it);\n    pri_last_evict = victim_priority;\n\n    return victim_id;\n  }\n};\n```\nUnique approach: Modification: Change 1: Replace 18 lines with 14 lines\nChange 2: Replace 12 lines with 12 lines, Alternative combined_score approach, Mixed iteration strategies\n\n### Inspiration 2 (Score: 0.8572, Type: High-Performer)\n```python\n#include <cstdint>\n#include <iomanip>\n#include <iostream>\n#include <set>\n#include <string>\n#include <unordered_map>\n\ntypedef uint64_t obj_id_t;\n\n/**\n * Implements the Greedy-Dual-Size-Frequency (GDSF) eviction policy.\n *\n * This class manages the cache eviction state. It tracks objects,\n * their sizes, and their frequencies to calculate a priority for\n * eviction. It evicts the object with the *lowest* priority.\n *\n * Priority (H-value) is calculated as: L + (Frequency / Size)\n * where 'L' is the priority of the last evicted item.\n */\nclass CacheManager {\nprivate:\n  /**\n   * Node stored in the priority queue (std::set).\n   *\n   * We use std::set as a min-priority queue. It stores nodes\n   * ordered by priority, then by a timestamp as a tie-breaker.\n   */\n  struct PQNode {\n    double priority;\n    uint64_t timestamp; // Tie-breaker, incremented on each access\n    obj_id_t id;\n\n    // Constructor\n    PQNode(double p, uint64_t ts, obj_id_t i)\n        : priority(p), timestamp(ts), id(i) {}\n\n    // Comparison operator for std::set\n    // Orders by priority (lowest first), then timestamp\n    bool operator<(const PQNode &other) const {\n      if (priority != other.priority) {\n        return priority < other.priority;\n      }\n      return timestamp < other.timestamp;\n    }\n  };\n\n  /**\n   * Metadata for each object stored in the cache.\n   *\n   * Stored as the value in the main `cache_objects` map.\n   */\n  struct CacheObject {\n    uint64_t size;\n    uint64_t frequency;\n    // An iterator pointing to this object's entry in the\n    // priority_queue set. This allows for O(log N) removal\n    // during a `find` operation.\n    std::set<PQNode>::iterator pq_iterator;\n  };\n\n  /**\n   * Main lookup map.\n   *\n   * Maps an object's ID to its metadata (size, freq, and\n   * iterator into the priority queue).\n   */\n  std::unordered_map<obj_id_t, CacheObject> cache_objects;\n\n  /**\n   * The priority queue.\n   *\n   * Implemented as an std::set to keep items sorted by priority\n   * and allow for efficient removal from anywhere in the queue.\n   * The item at `priority_queue.begin()` is the eviction victim.\n   */\n  std::set<PQNode> priority_queue;\n\n  /**\n   *  The 'L' value in GDSF.\n   *\n   * This is the priority of the last item that was evicted.\n   * It's used as the base priority for all new and re-prioritized items.\n   */\n  double pri_last_evict = 0.0;\n\n  /**\n   * A simple counter to use as a timestamp for tie-breaking.\n   *\n   * This ensures FIFO-like behavior for items with the same priority.\n   */\n  uint64_t request_counter = 0;\n\n  /**\n   * Helper function to calculate an object's priority (H-value).\n   *\n   * From the original code: pri = L + (freq * 1.0e6 / size)\n   * The 1.0e6 is a scaling factor to keep the (freq/size)\n   * component significant.\n   */\n  // Reduce scaling factor from 1.0e6 to 1.0e5 to minimize domination of frequency/size over recency\n  // Incorporate a recency boost for diversity and hot set adaptation\n  double calculate_priority(uint64_t freq, uint64_t size) {\n    double recency_boost = 0.12 * (request_counter % 7); // [0,0.72] steps\n    if (size == 0) {\n      return pri_last_evict + (double)(freq) * 1.0e5 + recency_boost;\n    }\n    return pri_last_evict + (double)(freq) * 1.0e5 / size + recency_boost;\n  }\n\npublic:\n  /**\n   * Default constructor.\n   */\n  CacheManager() = default;\n\n  /**\n   * Finds an object in the cache.\n   *\n   * If the object is found, its frequency is incremented, its\n   * priority is recalculated, and its position in the\n   * priority queue is updated.\n   *\n   * @param obj_id The ID of the object to find.\n   * @return true if the object was found (a hit), false otherwise (a miss).\n   */\n  bool find(obj_id_t obj_id) {\n    auto map_iter = cache_objects.find(obj_id);\n\n    if (map_iter == cache_objects.end()) {\n      return false;\n    }\n\n    CacheObject &obj = map_iter->second;\n    priority_queue.erase(obj.pq_iterator);\n    obj.frequency += 1;\n    double new_pri = calculate_priority(obj.frequency, obj.size);\n\n    PQNode new_node(new_pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    obj.pq_iterator = set_iter;\n\n    return true;\n  }\n\n  /**\n   * Inserts a new object into the cache.\n   *\n   * Assumes this is called after a `find` reported a miss.\n   * If the object already exists, this function will behave\n   * like `find()` and update its priority.\n   *\n   * @param obj_id The ID of the object to insert.\n   * @param obj_size The size of the object (required for GDSF).\n   */\n  void insert(obj_id_t obj_id, uint64_t obj_size) {\n    if (cache_objects.count(obj_id)) {\n      find(obj_id);\n      return;\n    }\n\n    CacheObject new_obj;\n    new_obj.size = obj_size;\n    // Adaptive initial frequency:\n    if (obj_size < 4096) {\n      new_obj.frequency = 2;\n    } else if (obj_size > 512*1024) {\n      new_obj.frequency = 2;\n    } else {\n      new_obj.frequency = 1;\n    }\n\n    double pri = calculate_priority(new_obj.frequency, new_obj.size);\n    PQNode new_node(pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    new_obj.pq_iterator = set_iter;\n    cache_objects[obj_id] = new_obj;\n  }\n\n  /**\n   * Selects, removes, and returns the victim object to evict.\n   *\n   * The victim is the object with the *lowest* priority, which\n   * will be at the beginning of the `std::set`.\n   *\n   * @return The obj_id_t of the evicted object. Returns 0 if\n   * the cache is empty.\n   */\n  obj_id_t evict() {\n    if (priority_queue.empty()) {\n      return 0;\n    }\n\n    auto victim_node_it = priority_queue.begin();\n    obj_id_t victim_id = victim_node_it->id;\n    double victim_priority = victim_node_it->priority;\n\n    cache_objects.erase(victim_id);\n    priority_queue.erase(victim_node_it);\n    pri_last_evict = victim_priority;\n\n    return victim_id;\n  }\n};\n```\nUnique approach: Modification: Change 1: Replace 6 lines with 8 lines\nChange 2: Replace 19 lines with 24 lines, Alternative miss_ratio_45 approach, Alternative miss_ratio_450 approach\n\n### Inspiration 3 (Score: 0.8559, Type: High-Performer)\n```python\n#include <cstdint>\n#include <iomanip>\n#include <iostream>\n#include <set>\n#include <string>\n#include <unordered_map>\n\ntypedef uint64_t obj_id_t;\n\n/**\n * Implements the Greedy-Dual-Size-Frequency (GDSF) eviction policy.\n *\n * This class manages the cache eviction state. It tracks objects,\n * their sizes, and their frequencies to calculate a priority for\n * eviction. It evicts the object with the *lowest* priority.\n *\n * Priority (H-value) is calculated as: L + (Frequency / Size)\n * where 'L' is the priority of the last evicted item.\n */\nclass CacheManager {\nprivate:\n  /**\n   * Node stored in the priority queue (std::set).\n   *\n   * We use std::set as a min-priority queue. It stores nodes\n   * ordered by priority, then by a timestamp as a tie-breaker.\n   */\n  struct PQNode {\n    double priority;\n    uint64_t timestamp; // Tie-breaker, incremented on each access\n    obj_id_t id;\n\n    // Constructor\n    PQNode(double p, uint64_t ts, obj_id_t i)\n        : priority(p), timestamp(ts), id(i) {}\n\n    // Comparison operator for std::set\n    // Orders by priority (lowest first), then timestamp\n    bool operator<(const PQNode &other) const {\n      if (priority != other.priority) {\n        return priority < other.priority;\n      }\n      return timestamp < other.timestamp;\n    }\n  };\n\n  /**\n   * Metadata for each object stored in the cache.\n   *\n   * Stored as the value in the main `cache_objects` map.\n   */\n  struct CacheObject {\n    uint64_t size;\n    uint64_t frequency;\n    // An iterator pointing to this object's entry in the\n    // priority_queue set. This allows for O(log N) removal\n    // during a `find` operation.\n    std::set<PQNode>::iterator pq_iterator;\n  };\n\n  /**\n   * Main lookup map.\n   *\n   * Maps an object's ID to its metadata (size, freq, and\n   * iterator into the priority queue).\n   */\n  std::unordered_map<obj_id_t, CacheObject> cache_objects;\n\n  /**\n   * The priority queue.\n   *\n   * Implemented as an std::set to keep items sorted by priority\n   * and allow for efficient removal from anywhere in the queue.\n   * The item at `priority_queue.begin()` is the eviction victim.\n   */\n  std::set<PQNode> priority_queue;\n\n  /**\n   *  The 'L' value in GDSF.\n   *\n   * This is the priority of the last item that was evicted.\n   * It's used as the base priority for all new and re-prioritized items.\n   */\n  double pri_last_evict = 0.0;\n\n  /**\n   * A simple counter to use as a timestamp for tie-breaking.\n   *\n   * This ensures FIFO-like behavior for items with the same priority.\n   */\n  uint64_t request_counter = 0;\n\n  /**\n   * Helper function to calculate an object's priority (H-value).\n   *\n   * From the original code: pri = L + (freq * 1.0e6 / size)\n   * The 1.0e6 is a scaling factor to keep the (freq/size)\n   * component significant.\n   */\n  // Reduce scaling factor from 1.0e6 to 1.0e5 to minimize domination of frequency/size over recency\n  double calculate_priority(uint64_t freq, uint64_t size) {\n    if (size == 0) {\n      return pri_last_evict + (double)(freq) * 1.0e5;\n    }\n    return pri_last_evict + (double)(freq) * 1.0e5 / size;\n  }\n\npublic:\n  /**\n   * Default constructor.\n   */\n  CacheManager() = default;\n\n  /**\n   * Finds an object in the cache.\n   *\n   * If the object is found, its frequency is incremented, its\n   * priority is recalculated, and its position in the\n   * priority queue is updated.\n   *\n   * @param obj_id The ID of the object to find.\n   * @return true if the object was found (a hit), false otherwise (a miss).\n   */\n  bool find(obj_id_t obj_id) {\n    auto map_iter = cache_objects.find(obj_id);\n\n    if (map_iter == cache_objects.end()) {\n      return false;\n    }\n\n    CacheObject &obj = map_iter->second;\n    priority_queue.erase(obj.pq_iterator);\n    obj.frequency += 1;\n    double new_pri = calculate_priority(obj.frequency, obj.size);\n\n    PQNode new_node(new_pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    obj.pq_iterator = set_iter;\n\n    return true;\n  }\n\n  /**\n   * Inserts a new object into the cache.\n   *\n   * Assumes this is called after a `find` reported a miss.\n   * If the object already exists, this function will behave\n   * like `find()` and update its priority.\n   *\n   * @param obj_id The ID of the object to insert.\n   * @param obj_size The size of the object (required for GDSF).\n   */\n  void insert(obj_id_t obj_id, uint64_t obj_size) {\n    if (cache_objects.count(obj_id)) {\n      find(obj_id);\n      return;\n    }\n\n    CacheObject new_obj;\n    new_obj.size = obj_size;\n    new_obj.frequency = 1;\n\n    // Favor recency on first insert: set freq=2 (was 1) for cold objects\n    double pri = calculate_priority(2, new_obj.size);\n    PQNode new_node(pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    new_obj.frequency = 2;\n    new_obj.pq_iterator = set_iter;\n    cache_objects[obj_id] = new_obj;\n  }\n\n  /**\n   * Selects, removes, and returns the victim object to evict.\n   *\n   * The victim is the object with the *lowest* priority, which\n   * will be at the beginning of the `std::set`.\n   *\n   * @return The obj_id_t of the evicted object. Returns 0 if\n   * the cache is empty.\n   */\n  obj_id_t evict() {\n    if (priority_queue.empty()) {\n      return 0;\n    }\n\n    auto victim_node_it = priority_queue.begin();\n    obj_id_t victim_id = victim_node_it->id;\n    double victim_priority = victim_node_it->priority;\n\n    cache_objects.erase(victim_id);\n    priority_queue.erase(victim_node_it);\n    pri_last_evict = victim_priority;\n\n    return victim_id;\n  }\n};\n```\nUnique approach: Modification: Change 1: Replace 6 lines with 7 lines\nChange 2: Replace 10 lines with 12 lines, Alternative miss_ratio_45 approach, Alternative miss_ratio_450 approach\n\n# Current Program\n```python\n#include <cstdint>\n#include <iomanip>\n#include <iostream>\n#include <set>\n#include <string>\n#include <unordered_map>\n\ntypedef uint64_t obj_id_t;\n\n/**\n * Implements the Greedy-Dual-Size-Frequency (GDSF) eviction policy.\n *\n * This class manages the cache eviction state. It tracks objects,\n * their sizes, and their frequencies to calculate a priority for\n * eviction. It evicts the object with the *lowest* priority.\n *\n * Priority (H-value) is calculated as: L + (Frequency / Size)\n * where 'L' is the priority of the last evicted item.\n */\nclass CacheManager {\nprivate:\n  /**\n   * Node stored in the priority queue (std::set).\n   *\n   * We use std::set as a min-priority queue. It stores nodes\n   * ordered by priority, then by a timestamp as a tie-breaker.\n   */\n  struct PQNode {\n    double priority;\n    uint64_t timestamp; // Tie-breaker, incremented on each access\n    obj_id_t id;\n\n    // Constructor\n    PQNode(double p, uint64_t ts, obj_id_t i)\n        : priority(p), timestamp(ts), id(i) {}\n\n    // Comparison operator for std::set\n    // Orders by priority (lowest first), then timestamp\n    bool operator<(const PQNode &other) const {\n      if (priority != other.priority) {\n        return priority < other.priority;\n      }\n      return timestamp < other.timestamp;\n    }\n  };\n\n  /**\n   * Metadata for each object stored in the cache.\n   *\n   * Stored as the value in the main `cache_objects` map.\n   */\n  struct CacheObject {\n    uint64_t size;\n    uint64_t frequency;\n    // An iterator pointing to this object's entry in the\n    // priority_queue set. This allows for O(log N) removal\n    // during a `find` operation.\n    std::set<PQNode>::iterator pq_iterator;\n  };\n\n  /**\n   * Main lookup map.\n   *\n   * Maps an object's ID to its metadata (size, freq, and\n   * iterator into the priority queue).\n   */\n  std::unordered_map<obj_id_t, CacheObject> cache_objects;\n\n  /**\n   * The priority queue.\n   *\n   * Implemented as an std::set to keep items sorted by priority\n   * and allow for efficient removal from anywhere in the queue.\n   * The item at `priority_queue.begin()` is the eviction victim.\n   */\n  std::set<PQNode> priority_queue;\n\n  /**\n   *  The 'L' value in GDSF.\n   *\n   * This is the priority of the last item that was evicted.\n   * It's used as the base priority for all new and re-prioritized items.\n   */\n  double pri_last_evict = 0.0;\n\n  /**\n   * A simple counter to use as a timestamp for tie-breaking.\n   *\n   * This ensures FIFO-like behavior for items with the same priority.\n   */\n  uint64_t request_counter = 0;\n\n  /**\n   * Helper function to calculate an object's priority (H-value).\n   *\n   * From the original code: pri = L + (freq * 1.0e6 / size)\n   * The 1.0e6 is a scaling factor to keep the (freq/size)\n   * component significant.\n   */\n  // Reduce scaling factor from 1.0e6 to 1.0e5 to minimize domination of frequency/size over recency\n  double calculate_priority(uint64_t freq, uint64_t size) {\n    if (size == 0) {\n      return pri_last_evict + (double)(freq) * 1.0e5;\n    }\n    return pri_last_evict + (double)(freq) * 1.0e5 / size;\n  }\n\npublic:\n  /**\n   * Default constructor.\n   */\n  CacheManager() = default;\n\n  /**\n   * Finds an object in the cache.\n   *\n   * If the object is found, its frequency is incremented, its\n   * priority is recalculated, and its position in the\n   * priority queue is updated.\n   *\n   * @param obj_id The ID of the object to find.\n   * @return true if the object was found (a hit), false otherwise (a miss).\n   */\n  bool find(obj_id_t obj_id) {\n    auto map_iter = cache_objects.find(obj_id);\n\n    if (map_iter == cache_objects.end()) {\n      return false;\n    }\n\n    CacheObject &obj = map_iter->second;\n    priority_queue.erase(obj.pq_iterator);\n    obj.frequency += 1;\n    double new_pri = calculate_priority(obj.frequency, obj.size);\n\n    PQNode new_node(new_pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    obj.pq_iterator = set_iter;\n\n    return true;\n  }\n\n  /**\n   * Inserts a new object into the cache.\n   *\n   * Assumes this is called after a `find` reported a miss.\n   * If the object already exists, this function will behave\n   * like `find()` and update its priority.\n   *\n   * @param obj_id The ID of the object to insert.\n   * @param obj_size The size of the object (required for GDSF).\n   */\n  void insert(obj_id_t obj_id, uint64_t obj_size) {\n    if (cache_objects.count(obj_id)) {\n      find(obj_id);\n      return;\n    }\n\n    CacheObject new_obj;\n    new_obj.size = obj_size;\n    // Give tiny objects a frequency boost to help small hot objects survive,\n    // and large objects a slight initial penalty.\n    if (obj_size < 4096) {\n      new_obj.frequency = 3;\n    } else if (obj_size > 512*1024) {\n      new_obj.frequency = 1;\n    } else {\n      new_obj.frequency = 2;\n    }\n\n    double pri = calculate_priority(new_obj.frequency, new_obj.size) + 0.08 * (request_counter % 5);\n    PQNode new_node(pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    new_obj.pq_iterator = set_iter;\n    cache_objects[obj_id] = new_obj;\n  }\n\n  /**\n   * Selects, removes, and returns the victim object to evict.\n   *\n   * The victim is the object with the *lowest* priority, which\n   * will be at the beginning of the `std::set`.\n   *\n   * @return The obj_id_t of the evicted object. Returns 0 if\n   * the cache is empty.\n   */\n  obj_id_t evict() {\n    if (priority_queue.empty()) {\n      return 0;\n    }\n\n    auto victim_node_it = priority_queue.begin();\n    obj_id_t victim_id = victim_node_it->id;\n    double victim_priority = victim_node_it->priority;\n\n    cache_objects.erase(victim_id);\n    priority_queue.erase(victim_node_it);\n    pri_last_evict = victim_priority;\n\n    return victim_id;\n  }\n};\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["<<<<<<< SEARCH\n  /**\n   * Inserts a new object into the cache.\n   *\n   * Assumes this is called after a `find` reported a miss.\n   * If the object already exists, this function will behave\n   * like `find()` and update its priority.\n   *\n   * @param obj_id The ID of the object to insert.\n   * @param obj_size The size of the object (required for GDSF).\n   */\n  void insert(obj_id_t obj_id, uint64_t obj_size) {\n    if (cache_objects.count(obj_id)) {\n      find(obj_id);\n      return;\n    }\n\n    CacheObject new_obj;\n    new_obj.size = obj_size;\n    // Give tiny objects a frequency boost to help small hot objects survive,\n    // and large objects a slight initial penalty.\n    if (obj_size < 4096) {\n      new_obj.frequency = 3;\n    } else if (obj_size > 512*1024) {\n      new_obj.frequency = 1;\n    } else {\n      new_obj.frequency = 2;\n    }\n\n    double pri = calculate_priority(new_obj.frequency, new_obj.size) + 0.08 * (request_counter % 5);\n    PQNode new_node(pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    new_obj.pq_iterator = set_iter;\n    cache_objects[obj_id] = new_obj;\n  }\n=======\n  /**\n   * Inserts a new object into the cache.\n   *\n   * Assumes this is called after a `find` reported a miss.\n   * If the object already exists, this function will behave\n   * like `find()` and update its priority.\n   *\n   * @param obj_id The ID of the object to insert.\n   * @param obj_size The size of the object (required for GDSF).\n   */\n  void insert(obj_id_t obj_id, uint64_t obj_size) {\n    if (cache_objects.count(obj_id)) {\n      find(obj_id);\n      return;\n    }\n\n    CacheObject new_obj;\n    new_obj.size = obj_size;\n    // Give tiny objects a frequency boost to help small hot objects survive,\n    // and large objects a slight initial penalty.\n    if (obj_size < 4096) {\n      new_obj.frequency = 3;\n    } else if (obj_size > 4 * 1024 * 1024) { // >=4MB gets a penalty, harder to keep huge objects\n      new_obj.frequency = 1;\n    } else if (obj_size > 256 * 1024) {      // 256KB-4MB get moderate frequency\n      new_obj.frequency = 2;\n    } else {\n      new_obj.frequency = 2;\n    }\n\n    // Add a recency/random jitter that is a bit more diverse for improved tie-breaking\n    double pri = calculate_priority(new_obj.frequency, new_obj.size) + 0.06 * (request_counter % 9);\n\n    PQNode new_node(pri, ++request_counter, obj_id);\n    auto [set_iter, inserted] = priority_queue.insert(new_node);\n\n    new_obj.pq_iterator = set_iter;\n    cache_objects[obj_id] = new_obj;\n  }\n>>>>>>> REPLACE"]}}, "artifacts_json": "{\"full_results_json\": \"{\\\"score\\\": 0.8561, \\\"results\\\": [{\\\"cache_name\\\": \\\"FullCodeEvolve\\\", \\\"cache_size_mb\\\": 4, \\\"n_miss\\\": 1183469, \\\"n_req\\\": 3275919, \\\"miss_ratio\\\": 0.3613, \\\"byte_miss_ratio\\\": 0.6319, \\\"runtime_seconds\\\": 10.451162}, {\\\"cache_name\\\": \\\"FullCodeEvolve\\\", \\\"cache_size_mb\\\": 45, \\\"n_miss\\\": 815715, \\\"n_req\\\": 3275919, \\\"miss_ratio\\\": 0.249, \\\"byte_miss_ratio\\\": 0.4907, \\\"runtime_seconds\\\": 10.451162}, {\\\"cache_name\\\": \\\"FullCodeEvolve\\\", \\\"cache_size_mb\\\": 450, \\\"n_miss\\\": 471262, \\\"n_req\\\": 3275919, \\\"miss_ratio\\\": 0.1439, \\\"byte_miss_ratio\\\": 0.2477, \\\"runtime_seconds\\\": 10.451162}]}\"}", "artifact_dir": null, "embedding": null}